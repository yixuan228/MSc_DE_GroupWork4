{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook2: Predicting CO2 emissions using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readme: In this notebook, NN models are constructed for CO2 Emission prediction, and the best model is selected and K-means validation is applied.\n",
    "\n",
    "- **Notebook content**:\n",
    "    - Design the architecture of NN and explore different model configuration\n",
    "\n",
    "    - Tune hyperparameters and select the best model\n",
    "\n",
    "- **Notebook Output**:\n",
    "\n",
    "    - Best model file\n",
    "\n",
    "    - The validation and test results of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"numpy<2\" torch torchvision scikit-learn\n",
    "# %pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# 1 plot related functions----------------\n",
    "# plot predict and true values on validation dataset\n",
    "def plot_pred_true(y_test, y_pred, ax):\n",
    "\n",
    "    data = pd.DataFrame({'y_obs': y_test, 'y_pred': y_pred})\n",
    "\n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    sns.scatterplot(data=data, x='y_obs', y='y_pred', s=10, ax=ax)\n",
    "    ax.plot(y_test, y_test, color='red', label='y=x')          # plot the line y=x\n",
    "    ax.set_title('Observed vs Predicted values in Test Dataset')   # title\n",
    "    ax.set_xlabel('Observed values')       # label for the x-axis\n",
    "    ax.set_ylabel('Predicted values')      # label for the y-axis\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# plot the loss value on training and validation dataset\n",
    "def plot_train_val_loss(train_loss, val_loss, ax):\n",
    "    \n",
    "    # ax.figure(figsize=(5, 5))\n",
    "\n",
    "    ax.plot(train_loss, label='train loss')\n",
    "    ax.plot(val_loss, label='val loss')\n",
    "    ax.set_title('Train vs Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# 2 Other functions---------------------\n",
    "# get the prediction and true values\n",
    "def model_prediction(model, val_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    target = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model(X)      # predicted value\n",
    "\n",
    "            pred.extend(y_pred.cpu().numpy())\n",
    "            target.extend(y.cpu().numpy())\n",
    "\n",
    "    # Merge all the predictions and targets\n",
    "    predictions = np.concatenate(pred, axis=0)\n",
    "    labels = np.concatenate(target, axis=0)\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Divide Traning and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "trainset_df = pd.read_csv('Dataset2_train.csv').dropna()\n",
    "testset_df = pd.read_csv('Dataset2_test.csv').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gearbox_Type</th>\n",
       "      <th>Gearbox_Number</th>\n",
       "      <th>Energy Consumption per Distance MJ/100km</th>\n",
       "      <th>Model Features_Flexible-fuel vehicle</th>\n",
       "      <th>Model Features_Four-wheel drive</th>\n",
       "      <th>Model Features_Long wheelbase</th>\n",
       "      <th>Model Features_Short wheelbase</th>\n",
       "      <th>Vehicle Class_FULL-SIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicle Class_SUV - SMALL</th>\n",
       "      <th>Vehicle Class_SUV - STANDARD</th>\n",
       "      <th>Vehicle Class_TWO-SEATER</th>\n",
       "      <th>Vehicle Class_VAN - CARGO</th>\n",
       "      <th>Vehicle Class_VAN - PASSENGER</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "      <th>CO2 Emissions(g/km)</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>434.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>NISSAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>287.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>HYUNDAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>321.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>307.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>TOYOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>454.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>JAGUAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>287.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>MINI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>5.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>526.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>NISSAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>283.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>TOYOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.854093</td>\n",
       "      <td>294.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NISSAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>347.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>RAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5907 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Engine Size(L)  Cylinders  Gearbox_Type  Gearbox_Number  \\\n",
       "0                4.0        6.0           1.0        5.000000   \n",
       "1                2.4        4.0           1.0        6.000000   \n",
       "2                2.0        4.0           1.0        8.000000   \n",
       "3                2.5        4.0           1.0        6.000000   \n",
       "4                5.0        8.0           1.0        8.000000   \n",
       "...              ...        ...           ...             ...   \n",
       "5902             2.0        4.0           1.0        6.000000   \n",
       "5903             5.6        8.0           1.0        7.000000   \n",
       "5904             3.5        6.0           1.0        6.000000   \n",
       "5905             2.5        4.0           1.0        6.854093   \n",
       "5906             3.0        6.0           1.0        8.000000   \n",
       "\n",
       "      Energy Consumption per Distance MJ/100km  \\\n",
       "0                                       434.34   \n",
       "1                                       287.28   \n",
       "2                                       321.48   \n",
       "3                                       307.80   \n",
       "4                                       454.86   \n",
       "...                                        ...   \n",
       "5902                                    287.28   \n",
       "5903                                    526.68   \n",
       "5904                                    283.86   \n",
       "5905                                    294.12   \n",
       "5906                                    347.40   \n",
       "\n",
       "      Model Features_Flexible-fuel vehicle  Model Features_Four-wheel drive  \\\n",
       "0                                      0.0                              0.0   \n",
       "1                                      0.0                              0.0   \n",
       "2                                      0.0                              0.0   \n",
       "3                                      0.0                              0.0   \n",
       "4                                      0.0                              0.0   \n",
       "...                                    ...                              ...   \n",
       "5902                                   0.0                              0.0   \n",
       "5903                                   0.0                              1.0   \n",
       "5904                                   0.0                              0.0   \n",
       "5905                                   0.0                              0.0   \n",
       "5906                                   0.0                              0.0   \n",
       "\n",
       "      Model Features_Long wheelbase  Model Features_Short wheelbase  \\\n",
       "0                               0.0                             0.0   \n",
       "1                               0.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             0.0   \n",
       "4                               1.0                             0.0   \n",
       "...                             ...                             ...   \n",
       "5902                            0.0                             0.0   \n",
       "5903                            0.0                             0.0   \n",
       "5904                            0.0                             0.0   \n",
       "5905                            0.0                             0.0   \n",
       "5906                            0.0                             0.0   \n",
       "\n",
       "      Vehicle Class_FULL-SIZE  ...  Vehicle Class_SUV - SMALL  \\\n",
       "0                         0.0  ...                        0.0   \n",
       "1                         1.0  ...                        0.0   \n",
       "2                         0.0  ...                        0.0   \n",
       "3                         0.0  ...                        1.0   \n",
       "4                         1.0  ...                        0.0   \n",
       "...                       ...  ...                        ...   \n",
       "5902                      0.0  ...                        0.0   \n",
       "5903                      0.0  ...                        0.0   \n",
       "5904                      0.0  ...                        0.0   \n",
       "5905                      0.0  ...                        1.0   \n",
       "5906                      0.0  ...                        0.0   \n",
       "\n",
       "      Vehicle Class_SUV - STANDARD  Vehicle Class_TWO-SEATER  \\\n",
       "0                              0.0                       0.0   \n",
       "1                              0.0                       0.0   \n",
       "2                              0.0                       0.0   \n",
       "3                              0.0                       0.0   \n",
       "4                              0.0                       0.0   \n",
       "...                            ...                       ...   \n",
       "5902                           0.0                       0.0   \n",
       "5903                           1.0                       0.0   \n",
       "5904                           1.0                       0.0   \n",
       "5905                           0.0                       0.0   \n",
       "5906                           0.0                       0.0   \n",
       "\n",
       "      Vehicle Class_VAN - CARGO  Vehicle Class_VAN - PASSENGER  Fuel Type_E  \\\n",
       "0                           0.0                            0.0          0.0   \n",
       "1                           0.0                            0.0          0.0   \n",
       "2                           0.0                            0.0          0.0   \n",
       "3                           0.0                            0.0          0.0   \n",
       "4                           0.0                            0.0          0.0   \n",
       "...                         ...                            ...          ...   \n",
       "5902                        0.0                            0.0          0.0   \n",
       "5903                        0.0                            0.0          0.0   \n",
       "5904                        0.0                            0.0          0.0   \n",
       "5905                        0.0                            0.0          0.0   \n",
       "5906                        0.0                            0.0          0.0   \n",
       "\n",
       "      Fuel Type_X  Fuel Type_Z  CO2 Emissions(g/km)     Make  \n",
       "0             1.0          0.0                299.0   NISSAN  \n",
       "1             1.0          0.0                193.0  HYUNDAI  \n",
       "2             0.0          1.0                221.0      BMW  \n",
       "3             1.0          0.0                212.0   TOYOTA  \n",
       "4             0.0          1.0                313.0   JAGUAR  \n",
       "...           ...          ...                  ...      ...  \n",
       "5902          0.0          1.0                197.0     MINI  \n",
       "5903          1.0          0.0                362.0   NISSAN  \n",
       "5904          1.0          0.0                193.0   TOYOTA  \n",
       "5905          1.0          0.0                198.0   NISSAN  \n",
       "5906          0.0          0.0                243.0      RAM  \n",
       "\n",
       "[5907 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset_df.drop(columns=['CO2 Emissions(g/km)', 'Make'])\n",
    "y_train = trainset_df['CO2 Emissions(g/km)']\n",
    "\n",
    "X_test = testset_df.drop(columns=['CO2 Emissions(g/km)', 'Make'])\n",
    "y_test = testset_df['CO2 Emissions(g/km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gearbox_Type</th>\n",
       "      <th>Gearbox_Number</th>\n",
       "      <th>Energy Consumption per Distance MJ/100km</th>\n",
       "      <th>Model Features_Flexible-fuel vehicle</th>\n",
       "      <th>Model Features_Four-wheel drive</th>\n",
       "      <th>Model Features_Long wheelbase</th>\n",
       "      <th>Model Features_Short wheelbase</th>\n",
       "      <th>Vehicle Class_FULL-SIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicle Class_STATION WAGON - SMALL</th>\n",
       "      <th>Vehicle Class_SUBCOMPACT</th>\n",
       "      <th>Vehicle Class_SUV - SMALL</th>\n",
       "      <th>Vehicle Class_SUV - STANDARD</th>\n",
       "      <th>Vehicle Class_TWO-SEATER</th>\n",
       "      <th>Vehicle Class_VAN - CARGO</th>\n",
       "      <th>Vehicle Class_VAN - PASSENGER</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>434.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>287.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>321.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>307.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>454.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>287.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>5.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>526.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>283.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.854093</td>\n",
       "      <td>294.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>347.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5907 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Engine Size(L)  Cylinders  Gearbox_Type  Gearbox_Number  \\\n",
       "0                4.0        6.0           1.0        5.000000   \n",
       "1                2.4        4.0           1.0        6.000000   \n",
       "2                2.0        4.0           1.0        8.000000   \n",
       "3                2.5        4.0           1.0        6.000000   \n",
       "4                5.0        8.0           1.0        8.000000   \n",
       "...              ...        ...           ...             ...   \n",
       "5902             2.0        4.0           1.0        6.000000   \n",
       "5903             5.6        8.0           1.0        7.000000   \n",
       "5904             3.5        6.0           1.0        6.000000   \n",
       "5905             2.5        4.0           1.0        6.854093   \n",
       "5906             3.0        6.0           1.0        8.000000   \n",
       "\n",
       "      Energy Consumption per Distance MJ/100km  \\\n",
       "0                                       434.34   \n",
       "1                                       287.28   \n",
       "2                                       321.48   \n",
       "3                                       307.80   \n",
       "4                                       454.86   \n",
       "...                                        ...   \n",
       "5902                                    287.28   \n",
       "5903                                    526.68   \n",
       "5904                                    283.86   \n",
       "5905                                    294.12   \n",
       "5906                                    347.40   \n",
       "\n",
       "      Model Features_Flexible-fuel vehicle  Model Features_Four-wheel drive  \\\n",
       "0                                      0.0                              0.0   \n",
       "1                                      0.0                              0.0   \n",
       "2                                      0.0                              0.0   \n",
       "3                                      0.0                              0.0   \n",
       "4                                      0.0                              0.0   \n",
       "...                                    ...                              ...   \n",
       "5902                                   0.0                              0.0   \n",
       "5903                                   0.0                              1.0   \n",
       "5904                                   0.0                              0.0   \n",
       "5905                                   0.0                              0.0   \n",
       "5906                                   0.0                              0.0   \n",
       "\n",
       "      Model Features_Long wheelbase  Model Features_Short wheelbase  \\\n",
       "0                               0.0                             0.0   \n",
       "1                               0.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             0.0   \n",
       "4                               1.0                             0.0   \n",
       "...                             ...                             ...   \n",
       "5902                            0.0                             0.0   \n",
       "5903                            0.0                             0.0   \n",
       "5904                            0.0                             0.0   \n",
       "5905                            0.0                             0.0   \n",
       "5906                            0.0                             0.0   \n",
       "\n",
       "      Vehicle Class_FULL-SIZE  ...  Vehicle Class_STATION WAGON - SMALL  \\\n",
       "0                         0.0  ...                                  0.0   \n",
       "1                         1.0  ...                                  0.0   \n",
       "2                         0.0  ...                                  0.0   \n",
       "3                         0.0  ...                                  0.0   \n",
       "4                         1.0  ...                                  0.0   \n",
       "...                       ...  ...                                  ...   \n",
       "5902                      0.0  ...                                  0.0   \n",
       "5903                      0.0  ...                                  0.0   \n",
       "5904                      0.0  ...                                  0.0   \n",
       "5905                      0.0  ...                                  0.0   \n",
       "5906                      0.0  ...                                  0.0   \n",
       "\n",
       "      Vehicle Class_SUBCOMPACT  Vehicle Class_SUV - SMALL  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          1.0                        0.0   \n",
       "3                          0.0                        1.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "5902                       1.0                        0.0   \n",
       "5903                       0.0                        0.0   \n",
       "5904                       0.0                        0.0   \n",
       "5905                       0.0                        1.0   \n",
       "5906                       0.0                        0.0   \n",
       "\n",
       "      Vehicle Class_SUV - STANDARD  Vehicle Class_TWO-SEATER  \\\n",
       "0                              0.0                       0.0   \n",
       "1                              0.0                       0.0   \n",
       "2                              0.0                       0.0   \n",
       "3                              0.0                       0.0   \n",
       "4                              0.0                       0.0   \n",
       "...                            ...                       ...   \n",
       "5902                           0.0                       0.0   \n",
       "5903                           1.0                       0.0   \n",
       "5904                           1.0                       0.0   \n",
       "5905                           0.0                       0.0   \n",
       "5906                           0.0                       0.0   \n",
       "\n",
       "      Vehicle Class_VAN - CARGO  Vehicle Class_VAN - PASSENGER  Fuel Type_E  \\\n",
       "0                           0.0                            0.0          0.0   \n",
       "1                           0.0                            0.0          0.0   \n",
       "2                           0.0                            0.0          0.0   \n",
       "3                           0.0                            0.0          0.0   \n",
       "4                           0.0                            0.0          0.0   \n",
       "...                         ...                            ...          ...   \n",
       "5902                        0.0                            0.0          0.0   \n",
       "5903                        0.0                            0.0          0.0   \n",
       "5904                        0.0                            0.0          0.0   \n",
       "5905                        0.0                            0.0          0.0   \n",
       "5906                        0.0                            0.0          0.0   \n",
       "\n",
       "      Fuel Type_X  Fuel Type_Z  \n",
       "0             1.0          0.0  \n",
       "1             1.0          0.0  \n",
       "2             0.0          1.0  \n",
       "3             1.0          0.0  \n",
       "4             0.0          1.0  \n",
       "...           ...          ...  \n",
       "5902          0.0          1.0  \n",
       "5903          1.0          0.0  \n",
       "5904          1.0          0.0  \n",
       "5905          1.0          0.0  \n",
       "5906          0.0          0.0  \n",
       "\n",
       "[5907 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup pipline for Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = X_train.columns[X_train.nunique() == 2].tolist()  \n",
    "numerical_columns = [col for col in X_train.columns if col not in binary_columns]\n",
    "\n",
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns)  # StandardScale\n",
    "    ], \n",
    "    remainder='passthrough'  # keep dummy variable\n",
    ")\n",
    "\n",
    "# Setup pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Train Dataset：\n",
      "   Engine Size(L)  Cylinders  Gearbox_Type  Gearbox_Number  \\\n",
      "0        0.612690   0.200638     -1.602571        0.771485   \n",
      "1       -0.567895  -0.889172     -0.750938       -0.943120   \n",
      "2       -0.863042  -0.889172      0.952329       -0.544375   \n",
      "3       -0.494109  -0.889172     -0.750938       -0.703873   \n",
      "4        1.350555   1.290448      0.952329        1.010732   \n",
      "\n",
      "   Energy Consumption per Distance MJ/100km  \\\n",
      "0                                       1.0   \n",
      "1                                       1.0   \n",
      "2                                       1.0   \n",
      "3                                       1.0   \n",
      "4                                       1.0   \n",
      "\n",
      "   Model Features_Flexible-fuel vehicle  Model Features_Four-wheel drive  \\\n",
      "0                                   0.0                              0.0   \n",
      "1                                   0.0                              0.0   \n",
      "2                                   0.0                              0.0   \n",
      "3                                   0.0                              0.0   \n",
      "4                                   0.0                              0.0   \n",
      "\n",
      "   Model Features_Long wheelbase  Model Features_Short wheelbase  \\\n",
      "0                            0.0                             0.0   \n",
      "1                            0.0                             0.0   \n",
      "2                            0.0                             0.0   \n",
      "3                            0.0                             0.0   \n",
      "4                            1.0                             0.0   \n",
      "\n",
      "   Vehicle Class_FULL-SIZE  ...  Vehicle Class_STATION WAGON - SMALL  \\\n",
      "0                      0.0  ...                                  0.0   \n",
      "1                      1.0  ...                                  0.0   \n",
      "2                      0.0  ...                                  0.0   \n",
      "3                      0.0  ...                                  0.0   \n",
      "4                      1.0  ...                                  0.0   \n",
      "\n",
      "   Vehicle Class_SUBCOMPACT  Vehicle Class_SUV - SMALL  \\\n",
      "0                       0.0                        0.0   \n",
      "1                       0.0                        0.0   \n",
      "2                       1.0                        0.0   \n",
      "3                       0.0                        1.0   \n",
      "4                       0.0                        0.0   \n",
      "\n",
      "   Vehicle Class_SUV - STANDARD  Vehicle Class_TWO-SEATER  \\\n",
      "0                           0.0                       0.0   \n",
      "1                           0.0                       0.0   \n",
      "2                           0.0                       0.0   \n",
      "3                           0.0                       0.0   \n",
      "4                           0.0                       0.0   \n",
      "\n",
      "   Vehicle Class_VAN - CARGO  Vehicle Class_VAN - PASSENGER  Fuel Type_E  \\\n",
      "0                        0.0                            0.0          0.0   \n",
      "1                        0.0                            0.0          0.0   \n",
      "2                        0.0                            0.0          0.0   \n",
      "3                        0.0                            0.0          0.0   \n",
      "4                        0.0                            0.0          0.0   \n",
      "\n",
      "   Fuel Type_X  Fuel Type_Z  \n",
      "0          1.0          0.0  \n",
      "1          1.0          0.0  \n",
      "2          0.0          1.0  \n",
      "3          1.0          0.0  \n",
      "4          0.0          1.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Processed Test Dataset：\n",
      "   Engine Size(L)  Cylinders  Gearbox_Type  Gearbox_Number  \\\n",
      "0        2.235994   1.290448      0.100696        1.927846   \n",
      "1        0.317543   0.200638     -0.750938        0.731610   \n",
      "2        0.760263   1.290448     -0.750938        2.326591   \n",
      "3       -0.863042  -0.889172      0.952329       -0.703873   \n",
      "4       -1.010615  -0.889172     -0.750938       -1.022869   \n",
      "\n",
      "   Energy Consumption per Distance MJ/100km  \\\n",
      "0                                       0.0   \n",
      "1                                       1.0   \n",
      "2                                       0.0   \n",
      "3                                       1.0   \n",
      "4                                       1.0   \n",
      "\n",
      "   Model Features_Flexible-fuel vehicle  Model Features_Four-wheel drive  \\\n",
      "0                                   0.0                              0.0   \n",
      "1                                   0.0                              0.0   \n",
      "2                                   0.0                              0.0   \n",
      "3                                   0.0                              0.0   \n",
      "4                                   0.0                              0.0   \n",
      "\n",
      "   Model Features_Long wheelbase  Model Features_Short wheelbase  \\\n",
      "0                            0.0                             0.0   \n",
      "1                            0.0                             0.0   \n",
      "2                            0.0                             0.0   \n",
      "3                            0.0                             0.0   \n",
      "4                            0.0                             0.0   \n",
      "\n",
      "   Vehicle Class_FULL-SIZE  ...  Vehicle Class_STATION WAGON - SMALL  \\\n",
      "0                      0.0  ...                                  0.0   \n",
      "1                      0.0  ...                                  0.0   \n",
      "2                      0.0  ...                                  0.0   \n",
      "3                      0.0  ...                                  0.0   \n",
      "4                      0.0  ...                                  1.0   \n",
      "\n",
      "   Vehicle Class_SUBCOMPACT  Vehicle Class_SUV - SMALL  \\\n",
      "0                       0.0                        0.0   \n",
      "1                       0.0                        1.0   \n",
      "2                       0.0                        0.0   \n",
      "3                       0.0                        1.0   \n",
      "4                       0.0                        0.0   \n",
      "\n",
      "   Vehicle Class_SUV - STANDARD  Vehicle Class_TWO-SEATER  \\\n",
      "0                           0.0                       1.0   \n",
      "1                           0.0                       0.0   \n",
      "2                           0.0                       1.0   \n",
      "3                           0.0                       0.0   \n",
      "4                           0.0                       0.0   \n",
      "\n",
      "   Vehicle Class_VAN - CARGO  Vehicle Class_VAN - PASSENGER  Fuel Type_E  \\\n",
      "0                        0.0                            0.0          0.0   \n",
      "1                        0.0                            0.0          0.0   \n",
      "2                        0.0                            0.0          0.0   \n",
      "3                        0.0                            0.0          0.0   \n",
      "4                        0.0                            0.0          0.0   \n",
      "\n",
      "   Fuel Type_X  Fuel Type_Z  \n",
      "0          0.0          1.0  \n",
      "1          1.0          0.0  \n",
      "2          0.0          1.0  \n",
      "3          0.0          1.0  \n",
      "4          1.0          0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(X_train) \n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "\n",
    "print(\"Processed Train Dataset：\")\n",
    "print(X_train_df.head())\n",
    "\n",
    "print(\"Processed Test Dataset：\")\n",
    "print(X_test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Dataloader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to Tensor\n",
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32) \n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Load the training data and validation data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_val_tensor,y_test_tensor)\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 64  # batch size\n",
    "\n",
    "# Create data loader\n",
    "train_Loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_Loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre: k-fold Import K-fold Cross-validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=20, shuffle=True, random_state=42) # Set randon seed to make sure the results are reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Use W&B Grid Search to Find Best NN Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\87383\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"47ea61c7ee69e2e0e1cc46ed5c31bd6168f9f9db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        # Initialise an empty list to hold layers\n",
    "        layers = []\n",
    "\n",
    "        # First layer: input to hidden\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Additional hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        # Output layer: hidden to output\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Calculate the sizes for train and validation splits\n",
    "num_total = len(train_dataset)\n",
    "num_train = int(0.9 * num_total)\n",
    "num_val = num_total - num_train\n",
    "\n",
    "# Split the dataset\n",
    "train_subset, val_subset = random_split(train_dataset, [num_train, num_val])\n",
    "\n",
    "# Create DataLoaders for each subset\n",
    "train_Loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_Loader = DataLoader(val_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hidden_units_options = [32, 64, 128]    # Numbers of neurons in each hidden layer\n",
    "hidden_layers_options = [2, 3, 4]       # Numbers of hidden layers\n",
    "learning_rates = [0.1, 0.01, 0.001]     # Learning rates\n",
    "\n",
    "max_epochs = 200  # Arbitrarily large; early stopping will likely stop earlier.\n",
    "patience = 5      # Early stopping patience\n",
    "\n",
    "input_size =  X_train_processed.shape[1]   # Input size \n",
    "output_size = 1             # Output size\n",
    "\n",
    "learning_rate = 0.02        # Learning rate\n",
    "n_epochs = 100 # Numebr of epochs\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()    # Mean Squared Error for Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "# Train epoch function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # for features, target in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "    for features, target in train_loader:\n",
    "        features, target = features.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features) # Forward pass\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step() # Update the weights\n",
    "\n",
    "        running_loss += loss.item() * features.size(0)\n",
    "\n",
    "    return running_loss / len(train_loader.dataset)\n",
    "\n",
    "# Validation epoch function\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, target in val_loader:\n",
    "            # print(featuresfeatures.size(0))\n",
    "            features, target = features.to(device), target.to(device)\n",
    "            # features = features.view(features.size(0), -1)\n",
    "\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item() * features.size(0)\n",
    "\n",
    "    return val_loss / len(val_loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060340-x8hivw0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x8hivw0g' target=\"_blank\">wild-sun-113</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x8hivw0g' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x8hivw0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 5684.9589 | Val Loss: 432.9472\n",
      "Epoch 002 | Train Loss: 227.0380 | Val Loss: 159.9093\n",
      "Epoch 003 | Train Loss: 97.2622 | Val Loss: 71.7838\n",
      "Epoch 004 | Train Loss: 40.0519 | Val Loss: 31.7289\n",
      "Epoch 005 | Train Loss: 20.9705 | Val Loss: 18.8927\n",
      "Epoch 006 | Train Loss: 17.4531 | Val Loss: 37.1671\n",
      "Epoch 007 | Train Loss: 45.2787 | Val Loss: 46.3617\n",
      "Epoch 008 | Train Loss: 25.7191 | Val Loss: 56.5196\n",
      "Epoch 009 | Train Loss: 20.3182 | Val Loss: 35.1532\n",
      "Epoch 010 | Train Loss: 22.6486 | Val Loss: 14.8951\n",
      "Epoch 011 | Train Loss: 15.5698 | Val Loss: 26.7951\n",
      "Epoch 012 | Train Loss: 17.1965 | Val Loss: 47.7210\n",
      "Epoch 013 | Train Loss: 41.4849 | Val Loss: 99.7631\n",
      "Epoch 014 | Train Loss: 40.4423 | Val Loss: 20.5432\n",
      "Epoch 015 | Train Loss: 26.2336 | Val Loss: 25.3169\n",
      "Early stopping triggered at epoch 15\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▂▂▁▁▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_loss</td><td>26.23361</td></tr><tr><td>val_loss</td><td>25.31687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sun-113</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x8hivw0g' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x8hivw0g</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060340-x8hivw0g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060345-lwcz7m87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/lwcz7m87' target=\"_blank\">comfy-moon-114</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/lwcz7m87' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/lwcz7m87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 26068.8764 | Val Loss: 1128.9832\n",
      "Epoch 002 | Train Loss: 814.8440 | Val Loss: 659.8560\n",
      "Epoch 003 | Train Loss: 519.4361 | Val Loss: 458.0310\n",
      "Epoch 004 | Train Loss: 367.9968 | Val Loss: 339.3757\n",
      "Epoch 005 | Train Loss: 271.5075 | Val Loss: 259.8137\n",
      "Epoch 006 | Train Loss: 210.2598 | Val Loss: 212.1234\n",
      "Epoch 007 | Train Loss: 170.2192 | Val Loss: 171.7975\n",
      "Epoch 008 | Train Loss: 138.4198 | Val Loss: 139.6888\n",
      "Epoch 009 | Train Loss: 109.2448 | Val Loss: 110.2083\n",
      "Epoch 010 | Train Loss: 84.4231 | Val Loss: 84.1718\n",
      "Epoch 011 | Train Loss: 62.2225 | Val Loss: 59.9747\n",
      "Epoch 012 | Train Loss: 44.3123 | Val Loss: 43.5192\n",
      "Epoch 013 | Train Loss: 31.7182 | Val Loss: 31.6957\n",
      "Epoch 014 | Train Loss: 23.1151 | Val Loss: 26.9741\n",
      "Epoch 015 | Train Loss: 17.1547 | Val Loss: 16.6460\n",
      "Epoch 016 | Train Loss: 13.4483 | Val Loss: 15.4543\n",
      "Epoch 017 | Train Loss: 11.6333 | Val Loss: 13.0735\n",
      "Epoch 018 | Train Loss: 11.2771 | Val Loss: 12.0606\n",
      "Epoch 019 | Train Loss: 10.3405 | Val Loss: 10.3606\n",
      "Epoch 020 | Train Loss: 9.8659 | Val Loss: 13.8454\n",
      "Epoch 021 | Train Loss: 10.3433 | Val Loss: 10.1007\n",
      "Epoch 022 | Train Loss: 10.2970 | Val Loss: 11.0499\n",
      "Epoch 023 | Train Loss: 10.5497 | Val Loss: 9.5614\n",
      "Epoch 024 | Train Loss: 9.4489 | Val Loss: 10.2134\n",
      "Epoch 025 | Train Loss: 9.6050 | Val Loss: 10.9536\n",
      "Epoch 026 | Train Loss: 10.0988 | Val Loss: 9.7172\n",
      "Epoch 027 | Train Loss: 9.7399 | Val Loss: 9.0385\n",
      "Epoch 028 | Train Loss: 9.8545 | Val Loss: 14.5497\n",
      "Epoch 029 | Train Loss: 10.1722 | Val Loss: 13.6124\n",
      "Epoch 030 | Train Loss: 11.7012 | Val Loss: 10.1376\n",
      "Epoch 031 | Train Loss: 9.9442 | Val Loss: 9.4924\n",
      "Epoch 032 | Train Loss: 9.2117 | Val Loss: 8.8370\n",
      "Epoch 033 | Train Loss: 9.6190 | Val Loss: 12.3014\n",
      "Epoch 034 | Train Loss: 10.4136 | Val Loss: 11.1460\n",
      "Epoch 035 | Train Loss: 9.6706 | Val Loss: 10.1977\n",
      "Epoch 036 | Train Loss: 9.7949 | Val Loss: 11.4892\n",
      "Epoch 037 | Train Loss: 10.0190 | Val Loss: 9.9095\n",
      "Early stopping triggered at epoch 37\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>37</td></tr><tr><td>train_loss</td><td>10.01897</td></tr><tr><td>val_loss</td><td>9.90947</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-moon-114</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/lwcz7m87' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/lwcz7m87</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060345-lwcz7m87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060356-x68fimxu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x68fimxu' target=\"_blank\">effortless-violet-115</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x68fimxu' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x68fimxu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 65576.9718 | Val Loss: 62728.3097\n",
      "Epoch 002 | Train Loss: 55512.4145 | Val Loss: 41811.6966\n",
      "Epoch 003 | Train Loss: 24698.7824 | Val Loss: 8732.1925\n",
      "Epoch 004 | Train Loss: 3720.6282 | Val Loss: 1948.1775\n",
      "Epoch 005 | Train Loss: 1638.8725 | Val Loss: 1460.2546\n",
      "Epoch 006 | Train Loss: 1273.9440 | Val Loss: 1182.4016\n",
      "Epoch 007 | Train Loss: 1042.9137 | Val Loss: 993.3123\n",
      "Epoch 008 | Train Loss: 885.9123 | Val Loss: 860.1931\n",
      "Epoch 009 | Train Loss: 768.8070 | Val Loss: 760.1403\n",
      "Epoch 010 | Train Loss: 678.5078 | Val Loss: 678.1964\n",
      "Epoch 011 | Train Loss: 603.7776 | Val Loss: 609.0133\n",
      "Epoch 012 | Train Loss: 541.6039 | Val Loss: 554.9296\n",
      "Epoch 013 | Train Loss: 491.6415 | Val Loss: 508.1561\n",
      "Epoch 014 | Train Loss: 449.5603 | Val Loss: 467.8793\n",
      "Epoch 015 | Train Loss: 414.3058 | Val Loss: 434.5980\n",
      "Epoch 016 | Train Loss: 382.9814 | Val Loss: 408.1806\n",
      "Epoch 017 | Train Loss: 357.4150 | Val Loss: 382.0040\n",
      "Epoch 018 | Train Loss: 334.4183 | Val Loss: 359.2484\n",
      "Epoch 019 | Train Loss: 314.3411 | Val Loss: 339.1964\n",
      "Epoch 020 | Train Loss: 296.5872 | Val Loss: 322.7104\n",
      "Epoch 021 | Train Loss: 280.3164 | Val Loss: 304.7332\n",
      "Epoch 022 | Train Loss: 265.3551 | Val Loss: 287.0798\n",
      "Epoch 023 | Train Loss: 251.3552 | Val Loss: 273.3592\n",
      "Epoch 024 | Train Loss: 238.3627 | Val Loss: 256.5903\n",
      "Epoch 025 | Train Loss: 225.0361 | Val Loss: 243.6395\n",
      "Epoch 026 | Train Loss: 213.7540 | Val Loss: 230.6408\n",
      "Epoch 027 | Train Loss: 202.4558 | Val Loss: 218.4885\n",
      "Epoch 028 | Train Loss: 192.5984 | Val Loss: 208.5372\n",
      "Epoch 029 | Train Loss: 182.9385 | Val Loss: 197.7620\n",
      "Epoch 030 | Train Loss: 174.3670 | Val Loss: 187.9760\n",
      "Epoch 031 | Train Loss: 165.3060 | Val Loss: 179.3432\n",
      "Epoch 032 | Train Loss: 157.4850 | Val Loss: 171.2980\n",
      "Epoch 033 | Train Loss: 150.5257 | Val Loss: 163.1302\n",
      "Epoch 034 | Train Loss: 144.0894 | Val Loss: 156.9194\n",
      "Epoch 035 | Train Loss: 137.9822 | Val Loss: 150.7377\n",
      "Epoch 036 | Train Loss: 131.9453 | Val Loss: 144.3494\n",
      "Epoch 037 | Train Loss: 126.4722 | Val Loss: 137.5722\n",
      "Epoch 038 | Train Loss: 121.0784 | Val Loss: 131.6276\n",
      "Epoch 039 | Train Loss: 115.7936 | Val Loss: 125.7418\n",
      "Epoch 040 | Train Loss: 110.4397 | Val Loss: 120.4962\n",
      "Epoch 041 | Train Loss: 105.9732 | Val Loss: 115.8791\n",
      "Epoch 042 | Train Loss: 101.1018 | Val Loss: 110.7454\n",
      "Epoch 043 | Train Loss: 96.5888 | Val Loss: 104.9627\n",
      "Epoch 044 | Train Loss: 92.2642 | Val Loss: 100.0600\n",
      "Epoch 045 | Train Loss: 87.3384 | Val Loss: 95.2137\n",
      "Epoch 046 | Train Loss: 83.3575 | Val Loss: 91.1903\n",
      "Epoch 047 | Train Loss: 79.2164 | Val Loss: 85.8074\n",
      "Epoch 048 | Train Loss: 75.0919 | Val Loss: 82.1331\n",
      "Epoch 049 | Train Loss: 70.9111 | Val Loss: 77.0170\n",
      "Epoch 050 | Train Loss: 67.3518 | Val Loss: 73.5419\n",
      "Epoch 051 | Train Loss: 63.4933 | Val Loss: 68.8209\n",
      "Epoch 052 | Train Loss: 59.8612 | Val Loss: 64.7533\n",
      "Epoch 053 | Train Loss: 56.2750 | Val Loss: 61.7360\n",
      "Epoch 054 | Train Loss: 53.0980 | Val Loss: 57.7224\n",
      "Epoch 055 | Train Loss: 49.6973 | Val Loss: 53.4060\n",
      "Epoch 056 | Train Loss: 46.4150 | Val Loss: 50.0083\n",
      "Epoch 057 | Train Loss: 43.4543 | Val Loss: 46.9335\n",
      "Epoch 058 | Train Loss: 40.6068 | Val Loss: 44.2927\n",
      "Epoch 059 | Train Loss: 37.8390 | Val Loss: 40.7348\n",
      "Epoch 060 | Train Loss: 35.3511 | Val Loss: 37.6553\n",
      "Epoch 061 | Train Loss: 32.9496 | Val Loss: 34.9085\n",
      "Epoch 062 | Train Loss: 30.6242 | Val Loss: 32.7106\n",
      "Epoch 063 | Train Loss: 28.3752 | Val Loss: 30.1850\n",
      "Epoch 064 | Train Loss: 26.3739 | Val Loss: 28.0348\n",
      "Epoch 065 | Train Loss: 24.6185 | Val Loss: 26.0142\n",
      "Epoch 066 | Train Loss: 23.3306 | Val Loss: 25.4149\n",
      "Epoch 067 | Train Loss: 22.0341 | Val Loss: 22.8712\n",
      "Epoch 068 | Train Loss: 19.9496 | Val Loss: 20.9495\n",
      "Epoch 069 | Train Loss: 18.5968 | Val Loss: 19.6201\n",
      "Epoch 070 | Train Loss: 17.8653 | Val Loss: 19.0687\n",
      "Epoch 071 | Train Loss: 16.6852 | Val Loss: 17.5267\n",
      "Epoch 072 | Train Loss: 15.8896 | Val Loss: 18.4011\n",
      "Epoch 073 | Train Loss: 15.0780 | Val Loss: 16.1386\n",
      "Epoch 074 | Train Loss: 14.5110 | Val Loss: 15.2562\n",
      "Epoch 075 | Train Loss: 13.7804 | Val Loss: 14.8469\n",
      "Epoch 076 | Train Loss: 13.3306 | Val Loss: 14.1639\n",
      "Epoch 077 | Train Loss: 12.9534 | Val Loss: 14.0487\n",
      "Epoch 078 | Train Loss: 12.5342 | Val Loss: 13.5286\n",
      "Epoch 079 | Train Loss: 12.2188 | Val Loss: 13.4690\n",
      "Epoch 080 | Train Loss: 11.8432 | Val Loss: 13.3258\n",
      "Epoch 081 | Train Loss: 11.6661 | Val Loss: 12.3321\n",
      "Epoch 082 | Train Loss: 11.2378 | Val Loss: 12.1132\n",
      "Epoch 083 | Train Loss: 11.1567 | Val Loss: 12.0855\n",
      "Epoch 084 | Train Loss: 10.7691 | Val Loss: 11.6250\n",
      "Epoch 085 | Train Loss: 10.7919 | Val Loss: 11.6245\n",
      "Epoch 086 | Train Loss: 10.6585 | Val Loss: 10.8804\n",
      "Epoch 087 | Train Loss: 10.2819 | Val Loss: 10.9477\n",
      "Epoch 088 | Train Loss: 10.1566 | Val Loss: 10.7185\n",
      "Epoch 089 | Train Loss: 9.8374 | Val Loss: 10.7219\n",
      "Epoch 090 | Train Loss: 9.8363 | Val Loss: 10.1611\n",
      "Epoch 091 | Train Loss: 9.8469 | Val Loss: 10.8780\n",
      "Epoch 092 | Train Loss: 9.7906 | Val Loss: 10.3354\n",
      "Epoch 093 | Train Loss: 9.6597 | Val Loss: 11.3353\n",
      "Epoch 094 | Train Loss: 9.6047 | Val Loss: 9.9605\n",
      "Epoch 095 | Train Loss: 9.4585 | Val Loss: 10.1468\n",
      "Epoch 096 | Train Loss: 9.4546 | Val Loss: 10.2355\n",
      "Epoch 097 | Train Loss: 9.3104 | Val Loss: 9.7654\n",
      "Epoch 098 | Train Loss: 9.2452 | Val Loss: 9.8564\n",
      "Epoch 099 | Train Loss: 9.0569 | Val Loss: 10.2415\n",
      "Epoch 100 | Train Loss: 9.2935 | Val Loss: 9.6886\n",
      "Epoch 101 | Train Loss: 9.1523 | Val Loss: 9.8493\n",
      "Epoch 102 | Train Loss: 9.0337 | Val Loss: 9.4248\n",
      "Epoch 103 | Train Loss: 9.1459 | Val Loss: 9.1457\n",
      "Epoch 104 | Train Loss: 9.0429 | Val Loss: 9.3558\n",
      "Epoch 105 | Train Loss: 8.8423 | Val Loss: 9.8506\n",
      "Epoch 106 | Train Loss: 8.9144 | Val Loss: 9.1216\n",
      "Epoch 107 | Train Loss: 8.9670 | Val Loss: 9.6392\n",
      "Epoch 108 | Train Loss: 9.1982 | Val Loss: 11.2825\n",
      "Epoch 109 | Train Loss: 8.9252 | Val Loss: 8.9790\n",
      "Epoch 110 | Train Loss: 8.8093 | Val Loss: 9.2645\n",
      "Epoch 111 | Train Loss: 9.0608 | Val Loss: 9.4345\n",
      "Epoch 112 | Train Loss: 8.8529 | Val Loss: 10.7375\n",
      "Epoch 113 | Train Loss: 8.9218 | Val Loss: 9.1278\n",
      "Epoch 114 | Train Loss: 8.4938 | Val Loss: 9.0978\n",
      "Early stopping triggered at epoch 114\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>114</td></tr><tr><td>train_loss</td><td>8.4938</td></tr><tr><td>val_loss</td><td>9.09779</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-violet-115</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x68fimxu' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/x68fimxu</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060356-x68fimxu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060419-3uimrg5a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/3uimrg5a' target=\"_blank\">stellar-paper-116</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/3uimrg5a' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/3uimrg5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 4295.6183 | Val Loss: 271.7341\n",
      "Epoch 002 | Train Loss: 181.5026 | Val Loss: 143.2667\n",
      "Epoch 003 | Train Loss: 82.1883 | Val Loss: 51.1509\n",
      "Epoch 004 | Train Loss: 38.8854 | Val Loss: 25.4730\n",
      "Epoch 005 | Train Loss: 29.6722 | Val Loss: 29.6445\n",
      "Epoch 006 | Train Loss: 53.5422 | Val Loss: 86.7614\n",
      "Epoch 007 | Train Loss: 63.3367 | Val Loss: 2162.7078\n",
      "Epoch 008 | Train Loss: 1324.3004 | Val Loss: 37.4312\n",
      "Epoch 009 | Train Loss: 15.6728 | Val Loss: 13.4048\n",
      "Epoch 010 | Train Loss: 13.2499 | Val Loss: 14.0461\n",
      "Epoch 011 | Train Loss: 13.1815 | Val Loss: 14.5213\n",
      "Epoch 012 | Train Loss: 12.1622 | Val Loss: 13.0980\n",
      "Epoch 013 | Train Loss: 14.8974 | Val Loss: 13.8936\n",
      "Epoch 014 | Train Loss: 10.7164 | Val Loss: 17.8415\n",
      "Epoch 015 | Train Loss: 17.6889 | Val Loss: 14.8234\n",
      "Epoch 016 | Train Loss: 13.0130 | Val Loss: 11.8546\n",
      "Epoch 017 | Train Loss: 15.5684 | Val Loss: 30.6732\n",
      "Epoch 018 | Train Loss: 16.8607 | Val Loss: 19.2989\n",
      "Epoch 019 | Train Loss: 12.8636 | Val Loss: 22.9074\n",
      "Epoch 020 | Train Loss: 26.6266 | Val Loss: 20.3177\n",
      "Epoch 021 | Train Loss: 13.2116 | Val Loss: 32.4301\n",
      "Early stopping triggered at epoch 21\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>21</td></tr><tr><td>train_loss</td><td>13.21163</td></tr><tr><td>val_loss</td><td>32.43015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-paper-116</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/3uimrg5a' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/3uimrg5a</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060419-3uimrg5a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060426-epvc5sdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/epvc5sdy' target=\"_blank\">sandy-brook-117</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/epvc5sdy' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/epvc5sdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 20279.8204 | Val Loss: 722.4582\n",
      "Epoch 002 | Train Loss: 487.7913 | Val Loss: 367.4550\n",
      "Epoch 003 | Train Loss: 251.4566 | Val Loss: 196.6059\n",
      "Epoch 004 | Train Loss: 126.0732 | Val Loss: 91.5757\n",
      "Epoch 005 | Train Loss: 53.2550 | Val Loss: 34.6878\n",
      "Epoch 006 | Train Loss: 23.7934 | Val Loss: 20.8677\n",
      "Epoch 007 | Train Loss: 15.9955 | Val Loss: 16.4916\n",
      "Epoch 008 | Train Loss: 13.6044 | Val Loss: 14.4082\n",
      "Epoch 009 | Train Loss: 11.5736 | Val Loss: 14.4514\n",
      "Epoch 010 | Train Loss: 12.5525 | Val Loss: 12.1480\n",
      "Epoch 011 | Train Loss: 11.1949 | Val Loss: 13.7477\n",
      "Epoch 012 | Train Loss: 11.7107 | Val Loss: 11.6691\n",
      "Epoch 013 | Train Loss: 10.8469 | Val Loss: 10.5330\n",
      "Epoch 014 | Train Loss: 10.5973 | Val Loss: 10.7159\n",
      "Epoch 015 | Train Loss: 10.4209 | Val Loss: 22.2321\n",
      "Epoch 016 | Train Loss: 11.0919 | Val Loss: 15.0724\n",
      "Epoch 017 | Train Loss: 10.8996 | Val Loss: 23.0034\n",
      "Epoch 018 | Train Loss: 10.5003 | Val Loss: 9.9176\n",
      "Epoch 019 | Train Loss: 9.9874 | Val Loss: 12.4416\n",
      "Epoch 020 | Train Loss: 11.1042 | Val Loss: 18.0678\n",
      "Epoch 021 | Train Loss: 11.6225 | Val Loss: 10.1560\n",
      "Epoch 022 | Train Loss: 10.6100 | Val Loss: 11.3818\n",
      "Epoch 023 | Train Loss: 10.3317 | Val Loss: 11.2881\n",
      "Early stopping triggered at epoch 23\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>23</td></tr><tr><td>train_loss</td><td>10.33166</td></tr><tr><td>val_loss</td><td>11.28811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-brook-117</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/epvc5sdy' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/epvc5sdy</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060426-epvc5sdy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060433-2n9rx4jc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/2n9rx4jc' target=\"_blank\">whole-voice-118</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/2n9rx4jc' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/2n9rx4jc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 64306.3498 | Val Loss: 54912.4839\n",
      "Epoch 002 | Train Loss: 21332.2009 | Val Loss: 1983.4479\n",
      "Epoch 003 | Train Loss: 1458.8974 | Val Loss: 1140.3168\n",
      "Epoch 004 | Train Loss: 927.2481 | Val Loss: 824.3544\n",
      "Epoch 005 | Train Loss: 696.1938 | Val Loss: 658.4606\n",
      "Epoch 006 | Train Loss: 556.0088 | Val Loss: 546.7618\n",
      "Epoch 007 | Train Loss: 460.6027 | Val Loss: 465.5658\n",
      "Epoch 008 | Train Loss: 394.3031 | Val Loss: 412.5969\n",
      "Epoch 009 | Train Loss: 343.4101 | Val Loss: 359.0078\n",
      "Epoch 010 | Train Loss: 299.9994 | Val Loss: 317.3631\n",
      "Epoch 011 | Train Loss: 265.6060 | Val Loss: 283.9456\n",
      "Epoch 012 | Train Loss: 235.5904 | Val Loss: 253.3727\n",
      "Epoch 013 | Train Loss: 210.1204 | Val Loss: 227.2596\n",
      "Epoch 014 | Train Loss: 187.7790 | Val Loss: 206.8068\n",
      "Epoch 015 | Train Loss: 169.1779 | Val Loss: 184.2058\n",
      "Epoch 016 | Train Loss: 153.2483 | Val Loss: 167.4818\n",
      "Epoch 017 | Train Loss: 139.0274 | Val Loss: 153.5259\n",
      "Epoch 018 | Train Loss: 126.9647 | Val Loss: 139.2969\n",
      "Epoch 019 | Train Loss: 114.7085 | Val Loss: 127.9861\n",
      "Epoch 020 | Train Loss: 105.2273 | Val Loss: 116.4690\n",
      "Epoch 021 | Train Loss: 95.8102 | Val Loss: 106.9490\n",
      "Epoch 022 | Train Loss: 87.0990 | Val Loss: 97.3870\n",
      "Epoch 023 | Train Loss: 78.9447 | Val Loss: 88.4327\n",
      "Epoch 024 | Train Loss: 71.1110 | Val Loss: 81.3677\n",
      "Epoch 025 | Train Loss: 64.8180 | Val Loss: 73.1991\n",
      "Epoch 026 | Train Loss: 57.8517 | Val Loss: 65.4710\n",
      "Epoch 027 | Train Loss: 52.0511 | Val Loss: 59.9463\n",
      "Epoch 028 | Train Loss: 47.1210 | Val Loss: 53.3104\n",
      "Epoch 029 | Train Loss: 41.3219 | Val Loss: 46.8081\n",
      "Epoch 030 | Train Loss: 36.4473 | Val Loss: 42.8736\n",
      "Epoch 031 | Train Loss: 33.0000 | Val Loss: 37.6366\n",
      "Epoch 032 | Train Loss: 29.1637 | Val Loss: 33.4851\n",
      "Epoch 033 | Train Loss: 26.0902 | Val Loss: 29.3744\n",
      "Epoch 034 | Train Loss: 23.2151 | Val Loss: 26.4250\n",
      "Epoch 035 | Train Loss: 20.9071 | Val Loss: 23.8853\n",
      "Epoch 036 | Train Loss: 19.2102 | Val Loss: 21.6070\n",
      "Epoch 037 | Train Loss: 17.3498 | Val Loss: 19.5752\n",
      "Epoch 038 | Train Loss: 15.9611 | Val Loss: 18.6399\n",
      "Epoch 039 | Train Loss: 14.9363 | Val Loss: 16.5780\n",
      "Epoch 040 | Train Loss: 13.8016 | Val Loss: 15.6602\n",
      "Epoch 041 | Train Loss: 13.2056 | Val Loss: 16.1847\n",
      "Epoch 042 | Train Loss: 12.8715 | Val Loss: 14.2307\n",
      "Epoch 043 | Train Loss: 12.1332 | Val Loss: 17.2905\n",
      "Epoch 044 | Train Loss: 12.0394 | Val Loss: 13.4433\n",
      "Epoch 045 | Train Loss: 11.5263 | Val Loss: 13.6861\n",
      "Epoch 046 | Train Loss: 11.0249 | Val Loss: 12.4319\n",
      "Epoch 047 | Train Loss: 10.7360 | Val Loss: 12.1562\n",
      "Epoch 048 | Train Loss: 10.4480 | Val Loss: 12.0020\n",
      "Epoch 049 | Train Loss: 10.2019 | Val Loss: 11.9733\n",
      "Epoch 050 | Train Loss: 10.1646 | Val Loss: 12.8583\n",
      "Epoch 051 | Train Loss: 9.8937 | Val Loss: 11.0786\n",
      "Epoch 052 | Train Loss: 9.8093 | Val Loss: 12.3770\n",
      "Epoch 053 | Train Loss: 9.8339 | Val Loss: 11.3986\n",
      "Epoch 054 | Train Loss: 9.5500 | Val Loss: 11.4135\n",
      "Epoch 055 | Train Loss: 9.4118 | Val Loss: 12.1658\n",
      "Epoch 056 | Train Loss: 9.3151 | Val Loss: 11.3399\n",
      "Early stopping triggered at epoch 56\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>56</td></tr><tr><td>train_loss</td><td>9.31515</td></tr><tr><td>val_loss</td><td>11.33985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-voice-118</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/2n9rx4jc' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/2n9rx4jc</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060433-2n9rx4jc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060448-13kix90y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/13kix90y' target=\"_blank\">drawn-monkey-119</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/13kix90y' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/13kix90y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 5601.5938 | Val Loss: 268.2481\n",
      "Epoch 002 | Train Loss: 191.7449 | Val Loss: 206.4569\n",
      "Epoch 003 | Train Loss: 96.3585 | Val Loss: 112.2993\n",
      "Epoch 004 | Train Loss: 49.7970 | Val Loss: 125.2713\n",
      "Epoch 005 | Train Loss: 47.1047 | Val Loss: 34.2078\n",
      "Epoch 006 | Train Loss: 33.1752 | Val Loss: 189.5582\n",
      "Epoch 007 | Train Loss: 44.2711 | Val Loss: 21.6726\n",
      "Epoch 008 | Train Loss: 116.6344 | Val Loss: 110.9597\n",
      "Epoch 009 | Train Loss: 71.8516 | Val Loss: 23.8139\n",
      "Epoch 010 | Train Loss: 320.9662 | Val Loss: 2115.7022\n",
      "Epoch 011 | Train Loss: 199.3344 | Val Loss: 22.8893\n",
      "Epoch 012 | Train Loss: 19.5109 | Val Loss: 29.2978\n",
      "Early stopping triggered at epoch 12\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▂▁▁▁▂▁▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>train_loss</td><td>19.51086</td></tr><tr><td>val_loss</td><td>29.29778</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-monkey-119</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/13kix90y' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/13kix90y</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060448-13kix90y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060452-4yxy2vng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/4yxy2vng' target=\"_blank\">peachy-dragon-120</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/4yxy2vng' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/4yxy2vng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 17588.8927 | Val Loss: 667.4967\n",
      "Epoch 002 | Train Loss: 453.4363 | Val Loss: 383.8189\n",
      "Epoch 003 | Train Loss: 277.4824 | Val Loss: 239.1008\n",
      "Epoch 004 | Train Loss: 178.5787 | Val Loss: 163.3355\n",
      "Epoch 005 | Train Loss: 124.9494 | Val Loss: 136.7734\n",
      "Epoch 006 | Train Loss: 87.6747 | Val Loss: 84.5271\n",
      "Epoch 007 | Train Loss: 57.1565 | Val Loss: 52.2982\n",
      "Epoch 008 | Train Loss: 36.9151 | Val Loss: 35.5532\n",
      "Epoch 009 | Train Loss: 26.5324 | Val Loss: 29.2467\n",
      "Epoch 010 | Train Loss: 18.2449 | Val Loss: 16.6761\n",
      "Epoch 011 | Train Loss: 13.3558 | Val Loss: 14.1585\n",
      "Epoch 012 | Train Loss: 12.3837 | Val Loss: 14.4308\n",
      "Epoch 013 | Train Loss: 12.1252 | Val Loss: 10.7948\n",
      "Epoch 014 | Train Loss: 10.1035 | Val Loss: 12.4716\n",
      "Epoch 015 | Train Loss: 11.8687 | Val Loss: 12.4799\n",
      "Epoch 016 | Train Loss: 11.2026 | Val Loss: 9.9119\n",
      "Epoch 017 | Train Loss: 10.7417 | Val Loss: 13.8019\n",
      "Epoch 018 | Train Loss: 12.0580 | Val Loss: 12.5308\n",
      "Epoch 019 | Train Loss: 11.5254 | Val Loss: 10.7822\n",
      "Epoch 020 | Train Loss: 10.3036 | Val Loss: 29.5274\n",
      "Epoch 021 | Train Loss: 14.0624 | Val Loss: 16.1170\n",
      "Early stopping triggered at epoch 21\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>21</td></tr><tr><td>train_loss</td><td>14.06243</td></tr><tr><td>val_loss</td><td>16.117</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-dragon-120</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/4yxy2vng' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/4yxy2vng</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060452-4yxy2vng\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060459-yj9bz8vv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yj9bz8vv' target=\"_blank\">peach-dawn-121</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yj9bz8vv' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yj9bz8vv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 63772.5039 | Val Loss: 49461.4415\n",
      "Epoch 002 | Train Loss: 11801.2012 | Val Loss: 1369.8855\n",
      "Epoch 003 | Train Loss: 1076.3710 | Val Loss: 841.3009\n",
      "Epoch 004 | Train Loss: 718.0974 | Val Loss: 636.3281\n",
      "Epoch 005 | Train Loss: 547.0719 | Val Loss: 514.0175\n",
      "Epoch 006 | Train Loss: 445.5437 | Val Loss: 432.4827\n",
      "Epoch 007 | Train Loss: 371.7794 | Val Loss: 370.1806\n",
      "Epoch 008 | Train Loss: 314.7434 | Val Loss: 319.2654\n",
      "Epoch 009 | Train Loss: 270.7148 | Val Loss: 277.4313\n",
      "Epoch 010 | Train Loss: 232.4131 | Val Loss: 241.7608\n",
      "Epoch 011 | Train Loss: 201.4410 | Val Loss: 212.4978\n",
      "Epoch 012 | Train Loss: 176.0741 | Val Loss: 186.9975\n",
      "Epoch 013 | Train Loss: 153.1820 | Val Loss: 164.0410\n",
      "Epoch 014 | Train Loss: 134.2261 | Val Loss: 145.1302\n",
      "Epoch 015 | Train Loss: 118.6029 | Val Loss: 128.0612\n",
      "Epoch 016 | Train Loss: 105.6780 | Val Loss: 114.6293\n",
      "Epoch 017 | Train Loss: 92.1165 | Val Loss: 99.8974\n",
      "Epoch 018 | Train Loss: 80.7879 | Val Loss: 86.8018\n",
      "Epoch 019 | Train Loss: 70.1306 | Val Loss: 77.2777\n",
      "Epoch 020 | Train Loss: 61.5049 | Val Loss: 68.2569\n",
      "Epoch 021 | Train Loss: 53.6461 | Val Loss: 58.1260\n",
      "Epoch 022 | Train Loss: 45.9162 | Val Loss: 49.2186\n",
      "Epoch 023 | Train Loss: 39.0201 | Val Loss: 42.2378\n",
      "Epoch 024 | Train Loss: 33.2431 | Val Loss: 36.6242\n",
      "Epoch 025 | Train Loss: 30.2592 | Val Loss: 30.5292\n",
      "Epoch 026 | Train Loss: 23.8766 | Val Loss: 26.8946\n",
      "Epoch 027 | Train Loss: 20.5444 | Val Loss: 22.1661\n",
      "Epoch 028 | Train Loss: 17.7310 | Val Loss: 19.6167\n",
      "Epoch 029 | Train Loss: 15.6450 | Val Loss: 16.9732\n",
      "Epoch 030 | Train Loss: 14.0365 | Val Loss: 17.4536\n",
      "Epoch 031 | Train Loss: 12.7640 | Val Loss: 13.9008\n",
      "Epoch 032 | Train Loss: 11.8867 | Val Loss: 13.0193\n",
      "Epoch 033 | Train Loss: 11.3426 | Val Loss: 12.2297\n",
      "Epoch 034 | Train Loss: 10.6726 | Val Loss: 12.1952\n",
      "Epoch 035 | Train Loss: 10.4125 | Val Loss: 11.4098\n",
      "Epoch 036 | Train Loss: 10.1781 | Val Loss: 11.0414\n",
      "Epoch 037 | Train Loss: 9.7979 | Val Loss: 12.1046\n",
      "Epoch 038 | Train Loss: 9.6778 | Val Loss: 10.7394\n",
      "Epoch 039 | Train Loss: 9.5825 | Val Loss: 12.8450\n",
      "Epoch 040 | Train Loss: 9.5388 | Val Loss: 12.1418\n",
      "Epoch 041 | Train Loss: 9.5674 | Val Loss: 10.4597\n",
      "Epoch 042 | Train Loss: 9.5592 | Val Loss: 10.0792\n",
      "Epoch 043 | Train Loss: 9.6102 | Val Loss: 11.9418\n",
      "Epoch 044 | Train Loss: 9.2355 | Val Loss: 10.0521\n",
      "Epoch 045 | Train Loss: 9.2262 | Val Loss: 10.5682\n",
      "Epoch 046 | Train Loss: 8.9531 | Val Loss: 11.0529\n",
      "Epoch 047 | Train Loss: 8.8594 | Val Loss: 10.1130\n",
      "Epoch 048 | Train Loss: 9.1901 | Val Loss: 11.3225\n",
      "Epoch 049 | Train Loss: 8.8768 | Val Loss: 9.4869\n",
      "Epoch 050 | Train Loss: 8.8711 | Val Loss: 11.2655\n",
      "Epoch 051 | Train Loss: 9.0900 | Val Loss: 11.2112\n",
      "Epoch 052 | Train Loss: 9.5029 | Val Loss: 14.2256\n",
      "Epoch 053 | Train Loss: 9.5442 | Val Loss: 9.4847\n",
      "Epoch 054 | Train Loss: 8.8958 | Val Loss: 10.1099\n",
      "Epoch 055 | Train Loss: 8.8858 | Val Loss: 12.2132\n",
      "Epoch 056 | Train Loss: 8.9032 | Val Loss: 9.8743\n",
      "Epoch 057 | Train Loss: 8.5515 | Val Loss: 10.8121\n",
      "Epoch 058 | Train Loss: 9.1494 | Val Loss: 10.3639\n",
      "Early stopping triggered at epoch 58\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>58</td></tr><tr><td>train_loss</td><td>9.14935</td></tr><tr><td>val_loss</td><td>10.36388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-dawn-121</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yj9bz8vv' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yj9bz8vv</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060459-yj9bz8vv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060515-z4h0gx8m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/z4h0gx8m' target=\"_blank\">winter-pine-122</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/z4h0gx8m' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/z4h0gx8m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 5367.0339 | Val Loss: 346.1573\n",
      "Epoch 002 | Train Loss: 213.4262 | Val Loss: 156.2706\n",
      "Epoch 003 | Train Loss: 95.1106 | Val Loss: 80.4394\n",
      "Epoch 004 | Train Loss: 48.9886 | Val Loss: 53.4198\n",
      "Epoch 005 | Train Loss: 32.0221 | Val Loss: 37.2005\n",
      "Epoch 006 | Train Loss: 20.5775 | Val Loss: 41.3516\n",
      "Epoch 007 | Train Loss: 32.6572 | Val Loss: 24.0800\n",
      "Epoch 008 | Train Loss: 17.9034 | Val Loss: 47.0996\n",
      "Epoch 009 | Train Loss: 20.8619 | Val Loss: 47.6163\n",
      "Epoch 010 | Train Loss: 19.9855 | Val Loss: 45.9665\n",
      "Epoch 011 | Train Loss: 44.8849 | Val Loss: 321.9528\n",
      "Epoch 012 | Train Loss: 156.9628 | Val Loss: 30.9424\n",
      "Early stopping triggered at epoch 12\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▂▂▁▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>train_loss</td><td>156.96284</td></tr><tr><td>val_loss</td><td>30.94239</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-pine-122</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/z4h0gx8m' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/z4h0gx8m</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060515-z4h0gx8m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060519-00if5jmz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/00if5jmz' target=\"_blank\">blooming-sky-123</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/00if5jmz' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/00if5jmz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 17770.6098 | Val Loss: 881.6893\n",
      "Epoch 002 | Train Loss: 564.1477 | Val Loss: 391.5139\n",
      "Epoch 003 | Train Loss: 245.7239 | Val Loss: 193.7192\n",
      "Epoch 004 | Train Loss: 147.2872 | Val Loss: 140.7518\n",
      "Epoch 005 | Train Loss: 109.2175 | Val Loss: 111.2636\n",
      "Epoch 006 | Train Loss: 82.2337 | Val Loss: 84.1766\n",
      "Epoch 007 | Train Loss: 62.3659 | Val Loss: 63.0341\n",
      "Epoch 008 | Train Loss: 45.4651 | Val Loss: 49.5748\n",
      "Epoch 009 | Train Loss: 32.4190 | Val Loss: 32.8602\n",
      "Epoch 010 | Train Loss: 22.3311 | Val Loss: 20.9996\n",
      "Epoch 011 | Train Loss: 15.3826 | Val Loss: 18.0510\n",
      "Epoch 012 | Train Loss: 11.6376 | Val Loss: 13.3004\n",
      "Epoch 013 | Train Loss: 11.1604 | Val Loss: 10.6053\n",
      "Epoch 014 | Train Loss: 10.5222 | Val Loss: 13.8182\n",
      "Epoch 015 | Train Loss: 10.7926 | Val Loss: 10.7086\n",
      "Epoch 016 | Train Loss: 9.6606 | Val Loss: 10.5752\n",
      "Epoch 017 | Train Loss: 10.3696 | Val Loss: 9.3397\n",
      "Epoch 018 | Train Loss: 9.5093 | Val Loss: 9.5888\n",
      "Epoch 019 | Train Loss: 9.3914 | Val Loss: 10.8612\n",
      "Epoch 020 | Train Loss: 9.7268 | Val Loss: 12.5199\n",
      "Epoch 021 | Train Loss: 10.1394 | Val Loss: 13.9346\n",
      "Epoch 022 | Train Loss: 11.4011 | Val Loss: 10.1950\n",
      "Early stopping triggered at epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss</td><td>11.40109</td></tr><tr><td>val_loss</td><td>10.19504</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sky-123</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/00if5jmz' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/00if5jmz</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060519-00if5jmz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060526-bujdih1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/bujdih1j' target=\"_blank\">swept-jazz-124</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/bujdih1j' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/bujdih1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 64072.6642 | Val Loss: 56038.3361\n",
      "Epoch 002 | Train Loss: 33850.1645 | Val Loss: 8380.4267\n",
      "Epoch 003 | Train Loss: 2776.7806 | Val Loss: 1567.9720\n",
      "Epoch 004 | Train Loss: 1327.9901 | Val Loss: 1197.5200\n",
      "Epoch 005 | Train Loss: 1048.4799 | Val Loss: 993.6215\n",
      "Epoch 006 | Train Loss: 878.0912 | Val Loss: 858.3244\n",
      "Epoch 007 | Train Loss: 766.2727 | Val Loss: 758.2129\n",
      "Epoch 008 | Train Loss: 685.4827 | Val Loss: 692.1457\n",
      "Epoch 009 | Train Loss: 619.3942 | Val Loss: 627.9913\n",
      "Epoch 010 | Train Loss: 564.5818 | Val Loss: 574.6131\n",
      "Epoch 011 | Train Loss: 516.4721 | Val Loss: 533.6092\n",
      "Epoch 012 | Train Loss: 476.1270 | Val Loss: 491.3686\n",
      "Epoch 013 | Train Loss: 439.9249 | Val Loss: 458.5085\n",
      "Epoch 014 | Train Loss: 406.2345 | Val Loss: 425.8267\n",
      "Epoch 015 | Train Loss: 375.8150 | Val Loss: 396.0359\n",
      "Epoch 016 | Train Loss: 349.2622 | Val Loss: 370.1260\n",
      "Epoch 017 | Train Loss: 325.9434 | Val Loss: 348.1144\n",
      "Epoch 018 | Train Loss: 304.2093 | Val Loss: 327.2303\n",
      "Epoch 019 | Train Loss: 284.5411 | Val Loss: 305.9915\n",
      "Epoch 020 | Train Loss: 265.6734 | Val Loss: 288.1694\n",
      "Epoch 021 | Train Loss: 249.4238 | Val Loss: 271.1863\n",
      "Epoch 022 | Train Loss: 233.2977 | Val Loss: 256.9378\n",
      "Epoch 023 | Train Loss: 219.8749 | Val Loss: 243.8610\n",
      "Epoch 024 | Train Loss: 206.7022 | Val Loss: 228.7601\n",
      "Epoch 025 | Train Loss: 194.1609 | Val Loss: 216.9864\n",
      "Epoch 026 | Train Loss: 182.9802 | Val Loss: 204.8683\n",
      "Epoch 027 | Train Loss: 171.7091 | Val Loss: 193.3430\n",
      "Epoch 028 | Train Loss: 161.6328 | Val Loss: 181.9581\n",
      "Epoch 029 | Train Loss: 151.6386 | Val Loss: 170.3820\n",
      "Epoch 030 | Train Loss: 141.3208 | Val Loss: 160.4236\n",
      "Epoch 031 | Train Loss: 132.2656 | Val Loss: 149.9436\n",
      "Epoch 032 | Train Loss: 123.6329 | Val Loss: 141.1571\n",
      "Epoch 033 | Train Loss: 115.3660 | Val Loss: 131.2902\n",
      "Epoch 034 | Train Loss: 106.8857 | Val Loss: 122.1894\n",
      "Epoch 035 | Train Loss: 99.0279 | Val Loss: 113.2464\n",
      "Epoch 036 | Train Loss: 91.4591 | Val Loss: 103.7054\n",
      "Epoch 037 | Train Loss: 83.4947 | Val Loss: 95.6382\n",
      "Epoch 038 | Train Loss: 76.5378 | Val Loss: 87.7624\n",
      "Epoch 039 | Train Loss: 69.7502 | Val Loss: 79.7819\n",
      "Epoch 040 | Train Loss: 63.3171 | Val Loss: 72.2275\n",
      "Epoch 041 | Train Loss: 56.8043 | Val Loss: 64.8366\n",
      "Epoch 042 | Train Loss: 51.0855 | Val Loss: 58.6439\n",
      "Epoch 043 | Train Loss: 45.7746 | Val Loss: 52.4212\n",
      "Epoch 044 | Train Loss: 40.6868 | Val Loss: 47.5675\n",
      "Epoch 045 | Train Loss: 36.2931 | Val Loss: 41.7531\n",
      "Epoch 046 | Train Loss: 32.2391 | Val Loss: 38.4132\n",
      "Epoch 047 | Train Loss: 28.5917 | Val Loss: 32.5388\n",
      "Epoch 048 | Train Loss: 25.1591 | Val Loss: 29.2581\n",
      "Epoch 049 | Train Loss: 22.4126 | Val Loss: 25.1857\n",
      "Epoch 050 | Train Loss: 19.7155 | Val Loss: 23.0644\n",
      "Epoch 051 | Train Loss: 17.6777 | Val Loss: 20.3047\n",
      "Epoch 052 | Train Loss: 16.0225 | Val Loss: 18.6641\n",
      "Epoch 053 | Train Loss: 14.4620 | Val Loss: 16.3816\n",
      "Epoch 054 | Train Loss: 13.2136 | Val Loss: 15.2180\n",
      "Epoch 055 | Train Loss: 12.4224 | Val Loss: 14.7298\n",
      "Epoch 056 | Train Loss: 11.5775 | Val Loss: 13.3722\n",
      "Epoch 057 | Train Loss: 10.8983 | Val Loss: 12.6199\n",
      "Epoch 058 | Train Loss: 10.6843 | Val Loss: 11.4766\n",
      "Epoch 059 | Train Loss: 10.0267 | Val Loss: 10.9951\n",
      "Epoch 060 | Train Loss: 9.7301 | Val Loss: 11.5615\n",
      "Epoch 061 | Train Loss: 9.5163 | Val Loss: 10.8047\n",
      "Epoch 062 | Train Loss: 9.3124 | Val Loss: 10.3508\n",
      "Epoch 063 | Train Loss: 9.0048 | Val Loss: 10.0177\n",
      "Epoch 064 | Train Loss: 8.8505 | Val Loss: 9.4242\n",
      "Epoch 065 | Train Loss: 8.6525 | Val Loss: 9.8558\n",
      "Epoch 066 | Train Loss: 8.7495 | Val Loss: 10.2730\n",
      "Epoch 067 | Train Loss: 8.5420 | Val Loss: 9.2437\n",
      "Epoch 068 | Train Loss: 8.4660 | Val Loss: 9.2784\n",
      "Epoch 069 | Train Loss: 8.6364 | Val Loss: 10.0309\n",
      "Epoch 070 | Train Loss: 8.4468 | Val Loss: 9.1297\n",
      "Epoch 071 | Train Loss: 8.6444 | Val Loss: 9.4279\n",
      "Epoch 072 | Train Loss: 8.4806 | Val Loss: 8.7027\n",
      "Epoch 073 | Train Loss: 8.2715 | Val Loss: 8.7550\n",
      "Epoch 074 | Train Loss: 8.2545 | Val Loss: 8.8146\n",
      "Epoch 075 | Train Loss: 8.3063 | Val Loss: 8.6609\n",
      "Epoch 076 | Train Loss: 8.1875 | Val Loss: 9.0612\n",
      "Epoch 077 | Train Loss: 8.1487 | Val Loss: 9.7948\n",
      "Epoch 078 | Train Loss: 8.1290 | Val Loss: 8.6643\n",
      "Epoch 079 | Train Loss: 8.1660 | Val Loss: 9.0658\n",
      "Epoch 080 | Train Loss: 8.3983 | Val Loss: 8.4253\n",
      "Epoch 081 | Train Loss: 8.2205 | Val Loss: 9.0527\n",
      "Epoch 082 | Train Loss: 8.4014 | Val Loss: 8.8862\n",
      "Epoch 083 | Train Loss: 8.1572 | Val Loss: 8.4256\n",
      "Epoch 084 | Train Loss: 8.0625 | Val Loss: 8.5685\n",
      "Epoch 085 | Train Loss: 8.4703 | Val Loss: 8.8836\n",
      "Early stopping triggered at epoch 85\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>85</td></tr><tr><td>train_loss</td><td>8.4703</td></tr><tr><td>val_loss</td><td>8.88359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-jazz-124</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/bujdih1j' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/bujdih1j</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060526-bujdih1j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060543-e7wz9s6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e7wz9s6u' target=\"_blank\">vocal-monkey-125</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e7wz9s6u' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e7wz9s6u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 23209.2925 | Val Loss: 327.7345\n",
      "Epoch 002 | Train Loss: 177.3181 | Val Loss: 87.9617\n",
      "Epoch 003 | Train Loss: 62.8053 | Val Loss: 55.5522\n",
      "Epoch 004 | Train Loss: 40.8645 | Val Loss: 65.8266\n",
      "Epoch 005 | Train Loss: 31.6286 | Val Loss: 22.0922\n",
      "Epoch 006 | Train Loss: 24.1179 | Val Loss: 20.8483\n",
      "Epoch 007 | Train Loss: 25.7577 | Val Loss: 44.7585\n",
      "Epoch 008 | Train Loss: 17.0221 | Val Loss: 24.4369\n",
      "Epoch 009 | Train Loss: 27.2246 | Val Loss: 39.5171\n",
      "Epoch 010 | Train Loss: 26.9798 | Val Loss: 15.9001\n",
      "Epoch 011 | Train Loss: 24.4974 | Val Loss: 20.2718\n",
      "Epoch 012 | Train Loss: 15.0915 | Val Loss: 11.6522\n",
      "Epoch 013 | Train Loss: 13.4629 | Val Loss: 47.7968\n",
      "Epoch 014 | Train Loss: 32.1661 | Val Loss: 14.9057\n",
      "Epoch 015 | Train Loss: 20.3240 | Val Loss: 26.0385\n",
      "Epoch 016 | Train Loss: 15.2420 | Val Loss: 13.1535\n",
      "Epoch 017 | Train Loss: 13.6203 | Val Loss: 13.0292\n",
      "Early stopping triggered at epoch 17\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▂▁▂▁▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_loss</td><td>13.6203</td></tr><tr><td>val_loss</td><td>13.02917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-monkey-125</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e7wz9s6u' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e7wz9s6u</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060543-e7wz9s6u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060550-klm6889b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/klm6889b' target=\"_blank\">magic-armadillo-126</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/klm6889b' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/klm6889b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 12452.4033 | Val Loss: 648.7354\n",
      "Epoch 002 | Train Loss: 392.8217 | Val Loss: 282.8874\n",
      "Epoch 003 | Train Loss: 192.6397 | Val Loss: 168.7127\n",
      "Epoch 004 | Train Loss: 120.3938 | Val Loss: 108.2264\n",
      "Epoch 005 | Train Loss: 72.2954 | Val Loss: 62.6671\n",
      "Epoch 006 | Train Loss: 38.2960 | Val Loss: 26.1397\n",
      "Epoch 007 | Train Loss: 18.8687 | Val Loss: 43.1324\n",
      "Epoch 008 | Train Loss: 16.3119 | Val Loss: 14.7597\n",
      "Epoch 009 | Train Loss: 12.6528 | Val Loss: 10.9432\n",
      "Epoch 010 | Train Loss: 11.1294 | Val Loss: 11.8990\n",
      "Epoch 011 | Train Loss: 12.9364 | Val Loss: 12.1980\n",
      "Epoch 012 | Train Loss: 11.3052 | Val Loss: 10.4135\n",
      "Epoch 013 | Train Loss: 10.2082 | Val Loss: 11.8111\n",
      "Epoch 014 | Train Loss: 14.0414 | Val Loss: 25.3828\n",
      "Epoch 015 | Train Loss: 14.5357 | Val Loss: 12.9395\n",
      "Epoch 016 | Train Loss: 11.4434 | Val Loss: 11.0041\n",
      "Epoch 017 | Train Loss: 15.0530 | Val Loss: 16.6070\n",
      "Early stopping triggered at epoch 17\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_loss</td><td>15.053</td></tr><tr><td>val_loss</td><td>16.60702</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-armadillo-126</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/klm6889b' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/klm6889b</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060550-klm6889b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060555-yf245ce6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yf245ce6' target=\"_blank\">warm-music-127</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yf245ce6' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yf245ce6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 57593.1719 | Val Loss: 21019.1942\n",
      "Epoch 002 | Train Loss: 3516.3086 | Val Loss: 1117.4006\n",
      "Epoch 003 | Train Loss: 885.9377 | Val Loss: 745.6730\n",
      "Epoch 004 | Train Loss: 635.4149 | Val Loss: 585.4353\n",
      "Epoch 005 | Train Loss: 506.2739 | Val Loss: 484.2035\n",
      "Epoch 006 | Train Loss: 417.9597 | Val Loss: 412.2882\n",
      "Epoch 007 | Train Loss: 350.8368 | Val Loss: 352.6594\n",
      "Epoch 008 | Train Loss: 299.5803 | Val Loss: 307.5783\n",
      "Epoch 009 | Train Loss: 258.6465 | Val Loss: 266.3292\n",
      "Epoch 010 | Train Loss: 222.0080 | Val Loss: 235.7577\n",
      "Epoch 011 | Train Loss: 192.6226 | Val Loss: 205.5038\n",
      "Epoch 012 | Train Loss: 168.1148 | Val Loss: 181.4671\n",
      "Epoch 013 | Train Loss: 147.2344 | Val Loss: 159.7488\n",
      "Epoch 014 | Train Loss: 129.7962 | Val Loss: 141.1110\n",
      "Epoch 015 | Train Loss: 114.4364 | Val Loss: 124.1949\n",
      "Epoch 016 | Train Loss: 98.6969 | Val Loss: 112.1648\n",
      "Epoch 017 | Train Loss: 87.4555 | Val Loss: 96.4904\n",
      "Epoch 018 | Train Loss: 76.1820 | Val Loss: 85.7151\n",
      "Epoch 019 | Train Loss: 65.8203 | Val Loss: 75.1708\n",
      "Epoch 020 | Train Loss: 57.3794 | Val Loss: 62.9881\n",
      "Epoch 021 | Train Loss: 48.7726 | Val Loss: 54.4368\n",
      "Epoch 022 | Train Loss: 41.9975 | Val Loss: 45.7314\n",
      "Epoch 023 | Train Loss: 35.1900 | Val Loss: 38.8095\n",
      "Epoch 024 | Train Loss: 29.8025 | Val Loss: 32.4670\n",
      "Epoch 025 | Train Loss: 24.9010 | Val Loss: 27.5250\n",
      "Epoch 026 | Train Loss: 21.4502 | Val Loss: 23.3663\n",
      "Epoch 027 | Train Loss: 18.6281 | Val Loss: 20.3074\n",
      "Epoch 028 | Train Loss: 16.4022 | Val Loss: 18.4727\n",
      "Epoch 029 | Train Loss: 15.1873 | Val Loss: 16.1027\n",
      "Epoch 030 | Train Loss: 13.7036 | Val Loss: 14.9335\n",
      "Epoch 031 | Train Loss: 12.5961 | Val Loss: 13.7323\n",
      "Epoch 032 | Train Loss: 12.0577 | Val Loss: 13.4813\n",
      "Epoch 033 | Train Loss: 11.4612 | Val Loss: 12.6313\n",
      "Epoch 034 | Train Loss: 11.1868 | Val Loss: 11.8667\n",
      "Epoch 035 | Train Loss: 11.0140 | Val Loss: 11.8413\n",
      "Epoch 036 | Train Loss: 11.2291 | Val Loss: 11.8517\n",
      "Epoch 037 | Train Loss: 10.3126 | Val Loss: 11.2914\n",
      "Epoch 038 | Train Loss: 10.1191 | Val Loss: 10.6266\n",
      "Epoch 039 | Train Loss: 9.7626 | Val Loss: 11.0636\n",
      "Epoch 040 | Train Loss: 9.8019 | Val Loss: 10.7681\n",
      "Epoch 041 | Train Loss: 9.6237 | Val Loss: 12.1787\n",
      "Epoch 042 | Train Loss: 9.7525 | Val Loss: 10.2319\n",
      "Epoch 043 | Train Loss: 9.3852 | Val Loss: 10.3952\n",
      "Epoch 044 | Train Loss: 9.4001 | Val Loss: 10.1465\n",
      "Epoch 045 | Train Loss: 9.1184 | Val Loss: 9.6974\n",
      "Epoch 046 | Train Loss: 9.6370 | Val Loss: 9.6917\n",
      "Epoch 047 | Train Loss: 9.2732 | Val Loss: 10.0941\n",
      "Epoch 048 | Train Loss: 9.0326 | Val Loss: 9.6425\n",
      "Epoch 049 | Train Loss: 9.1834 | Val Loss: 9.4348\n",
      "Epoch 050 | Train Loss: 8.7955 | Val Loss: 12.4648\n",
      "Epoch 051 | Train Loss: 9.6501 | Val Loss: 9.3046\n",
      "Epoch 052 | Train Loss: 8.6561 | Val Loss: 9.6842\n",
      "Epoch 053 | Train Loss: 8.6981 | Val Loss: 10.0742\n",
      "Epoch 054 | Train Loss: 8.7871 | Val Loss: 10.7455\n",
      "Epoch 055 | Train Loss: 9.2183 | Val Loss: 11.7481\n",
      "Epoch 056 | Train Loss: 8.6908 | Val Loss: 9.4333\n",
      "Early stopping triggered at epoch 56\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>56</td></tr><tr><td>train_loss</td><td>8.69078</td></tr><tr><td>val_loss</td><td>9.43328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-music-127</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yf245ce6' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/yf245ce6</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060555-yf245ce6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060609-a7h9fkub</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a7h9fkub' target=\"_blank\">floral-mountain-128</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a7h9fkub' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a7h9fkub</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 5324.8223 | Val Loss: 314.0550\n",
      "Epoch 002 | Train Loss: 190.1336 | Val Loss: 91.9837\n",
      "Epoch 003 | Train Loss: 84.1635 | Val Loss: 101.0192\n",
      "Epoch 004 | Train Loss: 212.9302 | Val Loss: 508.8862\n",
      "Epoch 005 | Train Loss: 215.3521 | Val Loss: 19.9742\n",
      "Epoch 006 | Train Loss: 28.7942 | Val Loss: 119.7837\n",
      "Epoch 007 | Train Loss: 626.9793 | Val Loss: 506.2651\n",
      "Epoch 008 | Train Loss: 189.7905 | Val Loss: 24.7084\n",
      "Epoch 009 | Train Loss: 18.8601 | Val Loss: 31.1361\n",
      "Epoch 010 | Train Loss: 15.4469 | Val Loss: 15.7467\n",
      "Epoch 011 | Train Loss: 33.4741 | Val Loss: 12.7756\n",
      "Epoch 012 | Train Loss: 23.9950 | Val Loss: 27.7649\n",
      "Epoch 013 | Train Loss: 20.8943 | Val Loss: 16.6221\n",
      "Epoch 014 | Train Loss: 23.7280 | Val Loss: 56.8748\n",
      "Epoch 015 | Train Loss: 38.4609 | Val Loss: 28.1741\n",
      "Epoch 016 | Train Loss: 1530.9791 | Val Loss: 1562.3311\n",
      "Early stopping triggered at epoch 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▃</td></tr><tr><td>val_loss</td><td>▂▁▁▃▁▁▃▁▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>train_loss</td><td>1530.97906</td></tr><tr><td>val_loss</td><td>1562.33113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-mountain-128</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a7h9fkub' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a7h9fkub</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060609-a7h9fkub\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060615-a5xgyis5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a5xgyis5' target=\"_blank\">vivid-cherry-129</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a5xgyis5' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a5xgyis5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 11039.4971 | Val Loss: 460.0582\n",
      "Epoch 002 | Train Loss: 277.9615 | Val Loss: 206.2116\n",
      "Epoch 003 | Train Loss: 129.9109 | Val Loss: 124.7597\n",
      "Epoch 004 | Train Loss: 75.1571 | Val Loss: 66.0882\n",
      "Epoch 005 | Train Loss: 45.0398 | Val Loss: 39.7234\n",
      "Epoch 006 | Train Loss: 27.7352 | Val Loss: 23.5057\n",
      "Epoch 007 | Train Loss: 16.3099 | Val Loss: 26.3645\n",
      "Epoch 008 | Train Loss: 15.7173 | Val Loss: 21.2576\n",
      "Epoch 009 | Train Loss: 12.2547 | Val Loss: 11.4101\n",
      "Epoch 010 | Train Loss: 12.8138 | Val Loss: 26.1883\n",
      "Epoch 011 | Train Loss: 14.7435 | Val Loss: 10.6170\n",
      "Epoch 012 | Train Loss: 11.1698 | Val Loss: 25.5292\n",
      "Epoch 013 | Train Loss: 14.8687 | Val Loss: 16.4916\n",
      "Epoch 014 | Train Loss: 13.6140 | Val Loss: 13.8669\n",
      "Epoch 015 | Train Loss: 11.2497 | Val Loss: 11.4731\n",
      "Epoch 016 | Train Loss: 13.2863 | Val Loss: 40.1406\n",
      "Early stopping triggered at epoch 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>train_loss</td><td>13.28633</td></tr><tr><td>val_loss</td><td>40.14064</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-cherry-129</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a5xgyis5' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/a5xgyis5</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060615-a5xgyis5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060620-rjstxb3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/rjstxb3b' target=\"_blank\">visionary-frog-130</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/rjstxb3b' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/rjstxb3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 53759.1546 | Val Loss: 2438.3561\n",
      "Epoch 002 | Train Loss: 1774.0786 | Val Loss: 906.3140\n",
      "Epoch 003 | Train Loss: 700.5962 | Val Loss: 591.5568\n",
      "Epoch 004 | Train Loss: 492.3784 | Val Loss: 457.9029\n",
      "Epoch 005 | Train Loss: 381.0114 | Val Loss: 369.3957\n",
      "Epoch 006 | Train Loss: 306.5175 | Val Loss: 308.0679\n",
      "Epoch 007 | Train Loss: 253.9776 | Val Loss: 261.5769\n",
      "Epoch 008 | Train Loss: 214.5005 | Val Loss: 223.6995\n",
      "Epoch 009 | Train Loss: 183.9476 | Val Loss: 194.4108\n",
      "Epoch 010 | Train Loss: 157.3571 | Val Loss: 169.2769\n",
      "Epoch 011 | Train Loss: 136.0495 | Val Loss: 149.1354\n",
      "Epoch 012 | Train Loss: 118.4579 | Val Loss: 132.5402\n",
      "Epoch 013 | Train Loss: 103.5787 | Val Loss: 114.6185\n",
      "Epoch 014 | Train Loss: 89.7270 | Val Loss: 99.6584\n",
      "Epoch 015 | Train Loss: 77.8267 | Val Loss: 85.7535\n",
      "Epoch 016 | Train Loss: 67.1675 | Val Loss: 74.2131\n",
      "Epoch 017 | Train Loss: 57.0450 | Val Loss: 64.0708\n",
      "Epoch 018 | Train Loss: 48.8119 | Val Loss: 53.8745\n",
      "Epoch 019 | Train Loss: 41.1759 | Val Loss: 45.7535\n",
      "Epoch 020 | Train Loss: 34.6589 | Val Loss: 37.7987\n",
      "Epoch 021 | Train Loss: 29.5801 | Val Loss: 33.3679\n",
      "Epoch 022 | Train Loss: 24.8544 | Val Loss: 29.1647\n",
      "Epoch 023 | Train Loss: 21.5231 | Val Loss: 23.1307\n",
      "Epoch 024 | Train Loss: 18.4820 | Val Loss: 21.2170\n",
      "Epoch 025 | Train Loss: 16.2921 | Val Loss: 18.2377\n",
      "Epoch 026 | Train Loss: 14.6237 | Val Loss: 16.0303\n",
      "Epoch 027 | Train Loss: 13.4949 | Val Loss: 14.6584\n",
      "Epoch 028 | Train Loss: 12.4245 | Val Loss: 13.8607\n",
      "Epoch 029 | Train Loss: 11.7966 | Val Loss: 12.5426\n",
      "Epoch 030 | Train Loss: 11.5596 | Val Loss: 12.4208\n",
      "Epoch 031 | Train Loss: 11.1437 | Val Loss: 11.8322\n",
      "Epoch 032 | Train Loss: 10.3953 | Val Loss: 11.6547\n",
      "Epoch 033 | Train Loss: 10.4466 | Val Loss: 13.0860\n",
      "Epoch 034 | Train Loss: 10.3921 | Val Loss: 11.6461\n",
      "Epoch 035 | Train Loss: 10.0099 | Val Loss: 11.8360\n",
      "Epoch 036 | Train Loss: 9.6589 | Val Loss: 10.8147\n",
      "Epoch 037 | Train Loss: 9.6021 | Val Loss: 11.2500\n",
      "Epoch 038 | Train Loss: 9.6254 | Val Loss: 9.9718\n",
      "Epoch 039 | Train Loss: 9.2524 | Val Loss: 10.3656\n",
      "Epoch 040 | Train Loss: 9.2012 | Val Loss: 9.7769\n",
      "Epoch 041 | Train Loss: 9.1304 | Val Loss: 10.0171\n",
      "Epoch 042 | Train Loss: 9.3512 | Val Loss: 10.5489\n",
      "Epoch 043 | Train Loss: 9.3811 | Val Loss: 9.6114\n",
      "Epoch 044 | Train Loss: 9.6758 | Val Loss: 9.3639\n",
      "Epoch 045 | Train Loss: 8.9496 | Val Loss: 12.7521\n",
      "Epoch 046 | Train Loss: 8.9934 | Val Loss: 9.7948\n",
      "Epoch 047 | Train Loss: 8.6449 | Val Loss: 9.7283\n",
      "Epoch 048 | Train Loss: 8.8216 | Val Loss: 10.6830\n",
      "Epoch 049 | Train Loss: 8.7540 | Val Loss: 12.7724\n",
      "Early stopping triggered at epoch 49\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>train_loss</td><td>8.75395</td></tr><tr><td>val_loss</td><td>12.77245</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-frog-130</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/rjstxb3b' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/rjstxb3b</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060620-rjstxb3b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060631-j3llifpb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/j3llifpb' target=\"_blank\">winter-sky-131</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/j3llifpb' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/j3llifpb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 3378.6415 | Val Loss: 144.1959\n",
      "Epoch 002 | Train Loss: 45.1557 | Val Loss: 64.9959\n",
      "Epoch 003 | Train Loss: 42.9957 | Val Loss: 70.2503\n",
      "Epoch 004 | Train Loss: 40.8652 | Val Loss: 45.5143\n",
      "Epoch 005 | Train Loss: 27.0341 | Val Loss: 34.4248\n",
      "Epoch 006 | Train Loss: 24.7401 | Val Loss: 14.6998\n",
      "Epoch 007 | Train Loss: 32.5678 | Val Loss: 38.9091\n",
      "Epoch 008 | Train Loss: 296.7142 | Val Loss: 363.7065\n",
      "Epoch 009 | Train Loss: 196.4815 | Val Loss: 34.7685\n",
      "Epoch 010 | Train Loss: 29.4653 | Val Loss: 556.5954\n",
      "Epoch 011 | Train Loss: 97.0979 | Val Loss: 37.2293\n",
      "Early stopping triggered at epoch 11\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>val_loss</td><td>▃▂▂▁▁▁▁▆▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>train_loss</td><td>97.09785</td></tr><tr><td>val_loss</td><td>37.22932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-sky-131</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/j3llifpb' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/j3llifpb</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060631-j3llifpb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060636-72nc61hx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/72nc61hx' target=\"_blank\">elated-moon-132</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/72nc61hx' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/72nc61hx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 12292.4601 | Val Loss: 625.4429\n",
      "Epoch 002 | Train Loss: 425.9248 | Val Loss: 341.8672\n",
      "Epoch 003 | Train Loss: 252.3089 | Val Loss: 228.6058\n",
      "Epoch 004 | Train Loss: 170.0089 | Val Loss: 166.9381\n",
      "Epoch 005 | Train Loss: 117.2839 | Val Loss: 112.7192\n",
      "Epoch 006 | Train Loss: 77.5715 | Val Loss: 79.9711\n",
      "Epoch 007 | Train Loss: 50.1096 | Val Loss: 41.8373\n",
      "Epoch 008 | Train Loss: 28.7001 | Val Loss: 27.3882\n",
      "Epoch 009 | Train Loss: 18.6430 | Val Loss: 17.6703\n",
      "Epoch 010 | Train Loss: 13.4588 | Val Loss: 21.5306\n",
      "Epoch 011 | Train Loss: 12.3153 | Val Loss: 13.4202\n",
      "Epoch 012 | Train Loss: 10.9686 | Val Loss: 22.3722\n",
      "Epoch 013 | Train Loss: 10.5370 | Val Loss: 11.6343\n",
      "Epoch 014 | Train Loss: 12.8524 | Val Loss: 14.3550\n",
      "Epoch 015 | Train Loss: 10.5238 | Val Loss: 12.4763\n",
      "Epoch 016 | Train Loss: 10.3104 | Val Loss: 16.5977\n",
      "Epoch 017 | Train Loss: 13.5028 | Val Loss: 13.5910\n",
      "Epoch 018 | Train Loss: 11.0643 | Val Loss: 11.6878\n",
      "Early stopping triggered at epoch 18\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>train_loss</td><td>11.06431</td></tr><tr><td>val_loss</td><td>11.68779</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-moon-132</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/72nc61hx' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/72nc61hx</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060636-72nc61hx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060641-tem9y5l7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/tem9y5l7' target=\"_blank\">celestial-sun-133</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/tem9y5l7' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/tem9y5l7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 57596.8936 | Val Loss: 33388.4358\n",
      "Epoch 002 | Train Loss: 9246.8692 | Val Loss: 1698.5603\n",
      "Epoch 003 | Train Loss: 1362.8211 | Val Loss: 1139.9209\n",
      "Epoch 004 | Train Loss: 967.7453 | Val Loss: 876.6559\n",
      "Epoch 005 | Train Loss: 763.1609 | Val Loss: 722.9293\n",
      "Epoch 006 | Train Loss: 634.1934 | Val Loss: 617.8983\n",
      "Epoch 007 | Train Loss: 541.0983 | Val Loss: 535.3746\n",
      "Epoch 008 | Train Loss: 469.8972 | Val Loss: 471.4196\n",
      "Epoch 009 | Train Loss: 410.3578 | Val Loss: 421.7941\n",
      "Epoch 010 | Train Loss: 363.3434 | Val Loss: 377.4794\n",
      "Epoch 011 | Train Loss: 323.4328 | Val Loss: 340.6127\n",
      "Epoch 012 | Train Loss: 289.9324 | Val Loss: 307.8573\n",
      "Epoch 013 | Train Loss: 261.3153 | Val Loss: 280.8860\n",
      "Epoch 014 | Train Loss: 237.4382 | Val Loss: 257.2701\n",
      "Epoch 015 | Train Loss: 215.7550 | Val Loss: 237.6346\n",
      "Epoch 016 | Train Loss: 198.2430 | Val Loss: 216.7328\n",
      "Epoch 017 | Train Loss: 183.0238 | Val Loss: 200.9625\n",
      "Epoch 018 | Train Loss: 166.7408 | Val Loss: 185.4869\n",
      "Epoch 019 | Train Loss: 154.2843 | Val Loss: 171.4250\n",
      "Epoch 020 | Train Loss: 142.3207 | Val Loss: 159.3566\n",
      "Epoch 021 | Train Loss: 131.6131 | Val Loss: 146.9072\n",
      "Epoch 022 | Train Loss: 121.6455 | Val Loss: 136.3248\n",
      "Epoch 023 | Train Loss: 112.1190 | Val Loss: 125.9156\n",
      "Epoch 024 | Train Loss: 102.1550 | Val Loss: 115.1382\n",
      "Epoch 025 | Train Loss: 92.8047 | Val Loss: 105.0389\n",
      "Epoch 026 | Train Loss: 84.5680 | Val Loss: 95.2913\n",
      "Epoch 027 | Train Loss: 76.7315 | Val Loss: 87.7872\n",
      "Epoch 028 | Train Loss: 69.5014 | Val Loss: 78.7790\n",
      "Epoch 029 | Train Loss: 62.7767 | Val Loss: 70.8613\n",
      "Epoch 030 | Train Loss: 56.0892 | Val Loss: 63.8825\n",
      "Epoch 031 | Train Loss: 49.9589 | Val Loss: 56.3743\n",
      "Epoch 032 | Train Loss: 44.3853 | Val Loss: 50.6791\n",
      "Epoch 033 | Train Loss: 39.0439 | Val Loss: 44.5734\n",
      "Epoch 034 | Train Loss: 34.6099 | Val Loss: 39.4946\n",
      "Epoch 035 | Train Loss: 30.3888 | Val Loss: 34.3271\n",
      "Epoch 036 | Train Loss: 26.2949 | Val Loss: 29.7272\n",
      "Epoch 037 | Train Loss: 23.2870 | Val Loss: 26.0491\n",
      "Epoch 038 | Train Loss: 20.4754 | Val Loss: 23.3625\n",
      "Epoch 039 | Train Loss: 18.3250 | Val Loss: 20.6785\n",
      "Epoch 040 | Train Loss: 17.0425 | Val Loss: 19.6496\n",
      "Epoch 041 | Train Loss: 15.0288 | Val Loss: 17.0834\n",
      "Epoch 042 | Train Loss: 13.7890 | Val Loss: 16.4927\n",
      "Epoch 043 | Train Loss: 12.8094 | Val Loss: 14.7380\n",
      "Epoch 044 | Train Loss: 11.9985 | Val Loss: 13.4672\n",
      "Epoch 045 | Train Loss: 11.1780 | Val Loss: 13.1398\n",
      "Epoch 046 | Train Loss: 10.7568 | Val Loss: 12.0814\n",
      "Epoch 047 | Train Loss: 10.5447 | Val Loss: 12.2135\n",
      "Epoch 048 | Train Loss: 10.0058 | Val Loss: 11.3943\n",
      "Epoch 049 | Train Loss: 10.0626 | Val Loss: 10.9366\n",
      "Epoch 050 | Train Loss: 9.8043 | Val Loss: 11.1154\n",
      "Epoch 051 | Train Loss: 9.6516 | Val Loss: 10.6573\n",
      "Epoch 052 | Train Loss: 9.2615 | Val Loss: 10.4726\n",
      "Epoch 053 | Train Loss: 9.1293 | Val Loss: 10.3669\n",
      "Epoch 054 | Train Loss: 9.0451 | Val Loss: 9.8104\n",
      "Epoch 055 | Train Loss: 8.8421 | Val Loss: 9.7634\n",
      "Epoch 056 | Train Loss: 8.9488 | Val Loss: 11.6853\n",
      "Epoch 057 | Train Loss: 9.0569 | Val Loss: 9.7213\n",
      "Epoch 058 | Train Loss: 8.8101 | Val Loss: 9.5449\n",
      "Epoch 059 | Train Loss: 8.6165 | Val Loss: 10.8193\n",
      "Epoch 060 | Train Loss: 8.9258 | Val Loss: 9.9463\n",
      "Epoch 061 | Train Loss: 8.5870 | Val Loss: 9.2114\n",
      "Epoch 062 | Train Loss: 8.6498 | Val Loss: 10.4034\n",
      "Epoch 063 | Train Loss: 8.3870 | Val Loss: 9.9291\n",
      "Epoch 064 | Train Loss: 8.3847 | Val Loss: 9.9277\n",
      "Epoch 065 | Train Loss: 8.5289 | Val Loss: 9.5398\n",
      "Epoch 066 | Train Loss: 8.3494 | Val Loss: 9.0239\n",
      "Epoch 067 | Train Loss: 8.4123 | Val Loss: 9.8344\n",
      "Epoch 068 | Train Loss: 8.6955 | Val Loss: 9.7891\n",
      "Epoch 069 | Train Loss: 8.4662 | Val Loss: 9.1937\n",
      "Epoch 070 | Train Loss: 8.2661 | Val Loss: 8.9517\n",
      "Epoch 071 | Train Loss: 8.3202 | Val Loss: 9.7712\n",
      "Epoch 072 | Train Loss: 8.3662 | Val Loss: 10.0524\n",
      "Epoch 073 | Train Loss: 8.7294 | Val Loss: 9.5686\n",
      "Epoch 074 | Train Loss: 8.2966 | Val Loss: 11.7419\n",
      "Epoch 075 | Train Loss: 8.6054 | Val Loss: 8.6749\n",
      "Epoch 076 | Train Loss: 8.4777 | Val Loss: 9.2417\n",
      "Epoch 077 | Train Loss: 8.6073 | Val Loss: 8.8177\n",
      "Epoch 078 | Train Loss: 8.4041 | Val Loss: 8.7432\n",
      "Epoch 079 | Train Loss: 8.3260 | Val Loss: 13.1921\n",
      "Epoch 080 | Train Loss: 8.5623 | Val Loss: 9.2483\n",
      "Early stopping triggered at epoch 80\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>train_loss</td><td>8.56229</td></tr><tr><td>val_loss</td><td>9.24832</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sun-133</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/tem9y5l7' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/tem9y5l7</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060641-tem9y5l7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060659-64014mph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/64014mph' target=\"_blank\">absurd-frost-134</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/64014mph' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/64014mph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 30470.1236 | Val Loss: 595.0307\n",
      "Epoch 002 | Train Loss: 299.3799 | Val Loss: 278.1076\n",
      "Epoch 003 | Train Loss: 135.0799 | Val Loss: 107.1041\n",
      "Epoch 004 | Train Loss: 72.4473 | Val Loss: 54.6222\n",
      "Epoch 005 | Train Loss: 39.6787 | Val Loss: 46.3924\n",
      "Epoch 006 | Train Loss: 36.9531 | Val Loss: 26.1136\n",
      "Epoch 007 | Train Loss: 21.9248 | Val Loss: 18.1360\n",
      "Epoch 008 | Train Loss: 18.5721 | Val Loss: 16.1833\n",
      "Epoch 009 | Train Loss: 23.9265 | Val Loss: 21.4578\n",
      "Epoch 010 | Train Loss: 26.1305 | Val Loss: 14.6025\n",
      "Epoch 011 | Train Loss: 15.2129 | Val Loss: 23.8940\n",
      "Epoch 012 | Train Loss: 26.0587 | Val Loss: 12.4633\n",
      "Epoch 013 | Train Loss: 16.2119 | Val Loss: 14.5961\n",
      "Epoch 014 | Train Loss: 18.4793 | Val Loss: 17.9011\n",
      "Epoch 015 | Train Loss: 17.1770 | Val Loss: 18.8891\n",
      "Epoch 016 | Train Loss: 40.5649 | Val Loss: 20.7226\n",
      "Epoch 017 | Train Loss: 25.5120 | Val Loss: 179.6507\n",
      "Early stopping triggered at epoch 17\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_loss</td><td>25.51196</td></tr><tr><td>val_loss</td><td>179.65065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-frost-134</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/64014mph' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/64014mph</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060659-64014mph\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060705-ta6cbt0p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ta6cbt0p' target=\"_blank\">spring-energy-135</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ta6cbt0p' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ta6cbt0p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 8095.1090 | Val Loss: 408.4089\n",
      "Epoch 002 | Train Loss: 230.4714 | Val Loss: 115.7787\n",
      "Epoch 003 | Train Loss: 40.4012 | Val Loss: 25.7817\n",
      "Epoch 004 | Train Loss: 16.8282 | Val Loss: 18.0906\n",
      "Epoch 005 | Train Loss: 13.4492 | Val Loss: 14.9072\n",
      "Epoch 006 | Train Loss: 13.0628 | Val Loss: 12.7941\n",
      "Epoch 007 | Train Loss: 11.7422 | Val Loss: 13.2890\n",
      "Epoch 008 | Train Loss: 10.8533 | Val Loss: 20.4058\n",
      "Epoch 009 | Train Loss: 13.4256 | Val Loss: 37.7030\n",
      "Epoch 010 | Train Loss: 14.0814 | Val Loss: 11.7266\n",
      "Epoch 011 | Train Loss: 11.8710 | Val Loss: 17.6871\n",
      "Epoch 012 | Train Loss: 14.3531 | Val Loss: 13.4756\n",
      "Epoch 013 | Train Loss: 12.0053 | Val Loss: 25.1319\n",
      "Epoch 014 | Train Loss: 12.1804 | Val Loss: 13.8048\n",
      "Epoch 015 | Train Loss: 11.6629 | Val Loss: 47.3507\n",
      "Early stopping triggered at epoch 15\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_loss</td><td>11.6629</td></tr><tr><td>val_loss</td><td>47.35074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-energy-135</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ta6cbt0p' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ta6cbt0p</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060705-ta6cbt0p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060711-e3mbv459</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e3mbv459' target=\"_blank\">stoic-sunset-136</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e3mbv459' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e3mbv459</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 39026.9549 | Val Loss: 2077.9757\n",
      "Epoch 002 | Train Loss: 1401.6604 | Val Loss: 836.0338\n",
      "Epoch 003 | Train Loss: 645.2891 | Val Loss: 546.7385\n",
      "Epoch 004 | Train Loss: 445.0852 | Val Loss: 414.9799\n",
      "Epoch 005 | Train Loss: 340.0925 | Val Loss: 333.7601\n",
      "Epoch 006 | Train Loss: 267.7119 | Val Loss: 268.1700\n",
      "Epoch 007 | Train Loss: 215.3385 | Val Loss: 220.4386\n",
      "Epoch 008 | Train Loss: 174.7301 | Val Loss: 180.6956\n",
      "Epoch 009 | Train Loss: 142.6270 | Val Loss: 153.4883\n",
      "Epoch 010 | Train Loss: 115.6774 | Val Loss: 122.0728\n",
      "Epoch 011 | Train Loss: 92.0799 | Val Loss: 95.7896\n",
      "Epoch 012 | Train Loss: 72.4263 | Val Loss: 75.3108\n",
      "Epoch 013 | Train Loss: 56.2390 | Val Loss: 56.3828\n",
      "Epoch 014 | Train Loss: 42.0979 | Val Loss: 41.6287\n",
      "Epoch 015 | Train Loss: 31.3935 | Val Loss: 31.4745\n",
      "Epoch 016 | Train Loss: 24.0586 | Val Loss: 23.2204\n",
      "Epoch 017 | Train Loss: 18.9750 | Val Loss: 20.1899\n",
      "Epoch 018 | Train Loss: 16.1634 | Val Loss: 16.5722\n",
      "Epoch 019 | Train Loss: 14.4566 | Val Loss: 14.9214\n",
      "Epoch 020 | Train Loss: 13.0367 | Val Loss: 14.1583\n",
      "Epoch 021 | Train Loss: 12.4313 | Val Loss: 12.9207\n",
      "Epoch 022 | Train Loss: 11.6405 | Val Loss: 12.9680\n",
      "Epoch 023 | Train Loss: 11.1813 | Val Loss: 12.9471\n",
      "Epoch 024 | Train Loss: 11.0147 | Val Loss: 11.6717\n",
      "Epoch 025 | Train Loss: 10.2511 | Val Loss: 11.0472\n",
      "Epoch 026 | Train Loss: 10.1275 | Val Loss: 13.0101\n",
      "Epoch 027 | Train Loss: 9.7722 | Val Loss: 10.4935\n",
      "Epoch 028 | Train Loss: 9.5471 | Val Loss: 10.0089\n",
      "Epoch 029 | Train Loss: 9.4950 | Val Loss: 11.5710\n",
      "Epoch 030 | Train Loss: 9.6025 | Val Loss: 11.5988\n",
      "Epoch 031 | Train Loss: 9.2706 | Val Loss: 11.2233\n",
      "Epoch 032 | Train Loss: 9.0024 | Val Loss: 9.8498\n",
      "Epoch 033 | Train Loss: 8.8504 | Val Loss: 9.6045\n",
      "Epoch 034 | Train Loss: 8.5857 | Val Loss: 10.7440\n",
      "Epoch 035 | Train Loss: 8.6101 | Val Loss: 9.8262\n",
      "Epoch 036 | Train Loss: 8.8099 | Val Loss: 9.6046\n",
      "Epoch 037 | Train Loss: 8.8354 | Val Loss: 9.2216\n",
      "Epoch 038 | Train Loss: 8.3318 | Val Loss: 9.4206\n",
      "Epoch 039 | Train Loss: 8.6844 | Val Loss: 9.3612\n",
      "Epoch 040 | Train Loss: 8.2419 | Val Loss: 9.5842\n",
      "Epoch 041 | Train Loss: 8.5063 | Val Loss: 9.1184\n",
      "Epoch 042 | Train Loss: 8.5020 | Val Loss: 13.4304\n",
      "Epoch 043 | Train Loss: 8.2934 | Val Loss: 11.4194\n",
      "Epoch 044 | Train Loss: 8.3709 | Val Loss: 9.5492\n",
      "Epoch 045 | Train Loss: 8.8647 | Val Loss: 9.3460\n",
      "Epoch 046 | Train Loss: 8.0211 | Val Loss: 11.0085\n",
      "Early stopping triggered at epoch 46\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>46</td></tr><tr><td>train_loss</td><td>8.0211</td></tr><tr><td>val_loss</td><td>11.00851</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-sunset-136</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e3mbv459' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/e3mbv459</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060711-e3mbv459\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060723-ndk6yxso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ndk6yxso' target=\"_blank\">stoic-eon-137</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ndk6yxso' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ndk6yxso</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 84013.3975 | Val Loss: 822.6130\n",
      "Epoch 002 | Train Loss: 337.7680 | Val Loss: 415.3241\n",
      "Epoch 003 | Train Loss: 342.3567 | Val Loss: 334.4990\n",
      "Epoch 004 | Train Loss: 115.3894 | Val Loss: 94.3244\n",
      "Epoch 005 | Train Loss: 75.9377 | Val Loss: 57.7822\n",
      "Epoch 006 | Train Loss: 198.2109 | Val Loss: 76.6740\n",
      "Epoch 007 | Train Loss: 68.7310 | Val Loss: 37.2204\n",
      "Epoch 008 | Train Loss: 74.4063 | Val Loss: 64.0750\n",
      "Epoch 009 | Train Loss: 52.0104 | Val Loss: 501.2241\n",
      "Epoch 010 | Train Loss: 68.0148 | Val Loss: 105.4707\n",
      "Epoch 011 | Train Loss: 61.2055 | Val Loss: 65.9701\n",
      "Epoch 012 | Train Loss: 39.8282 | Val Loss: 30.1500\n",
      "Epoch 013 | Train Loss: 43.2691 | Val Loss: 64.4885\n",
      "Epoch 014 | Train Loss: 25.5895 | Val Loss: 71.0081\n",
      "Epoch 015 | Train Loss: 25.4420 | Val Loss: 88.0273\n",
      "Epoch 016 | Train Loss: 118.8705 | Val Loss: 106.3131\n",
      "Epoch 017 | Train Loss: 53.1336 | Val Loss: 72.6272\n",
      "Early stopping triggered at epoch 17\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▂▁▁▁▁▅▂▁▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_loss</td><td>53.13361</td></tr><tr><td>val_loss</td><td>72.62718</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-eon-137</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ndk6yxso' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/ndk6yxso</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060723-ndk6yxso\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060728-d6p9veft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/d6p9veft' target=\"_blank\">scarlet-smoke-138</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/d6p9veft' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/d6p9veft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 8040.1402 | Val Loss: 357.3326\n",
      "Epoch 002 | Train Loss: 191.1112 | Val Loss: 144.3256\n",
      "Epoch 003 | Train Loss: 88.0819 | Val Loss: 68.4493\n",
      "Epoch 004 | Train Loss: 39.1414 | Val Loss: 28.7924\n",
      "Epoch 005 | Train Loss: 21.9119 | Val Loss: 18.3308\n",
      "Epoch 006 | Train Loss: 17.7311 | Val Loss: 20.1609\n",
      "Epoch 007 | Train Loss: 13.2779 | Val Loss: 15.7930\n",
      "Epoch 008 | Train Loss: 13.9569 | Val Loss: 17.3220\n",
      "Epoch 009 | Train Loss: 12.0874 | Val Loss: 16.1674\n",
      "Epoch 010 | Train Loss: 15.2808 | Val Loss: 22.2701\n",
      "Epoch 011 | Train Loss: 22.8963 | Val Loss: 14.4589\n",
      "Epoch 012 | Train Loss: 13.7037 | Val Loss: 26.7484\n",
      "Epoch 013 | Train Loss: 16.7572 | Val Loss: 16.4580\n",
      "Epoch 014 | Train Loss: 14.0089 | Val Loss: 12.0922\n",
      "Epoch 015 | Train Loss: 11.4703 | Val Loss: 39.8476\n",
      "Epoch 016 | Train Loss: 17.3945 | Val Loss: 25.9978\n",
      "Epoch 017 | Train Loss: 15.9247 | Val Loss: 14.9919\n",
      "Epoch 018 | Train Loss: 13.9009 | Val Loss: 39.7696\n",
      "Epoch 019 | Train Loss: 17.7258 | Val Loss: 30.4365\n",
      "Early stopping triggered at epoch 19\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>17.72577</td></tr><tr><td>val_loss</td><td>30.43645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-smoke-138</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/d6p9veft' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/d6p9veft</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060728-d6p9veft\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\MSc_DE_GroupWork4\\Scripts\\wandb\\run-20250321_060735-kx5oxaxg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/kx5oxaxg' target=\"_blank\">comfy-sound-139</a></strong> to <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/kx5oxaxg' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/kx5oxaxg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 31376.1690 | Val Loss: 1373.6425\n",
      "Epoch 002 | Train Loss: 791.4225 | Val Loss: 543.4087\n",
      "Epoch 003 | Train Loss: 419.9455 | Val Loss: 386.3143\n",
      "Epoch 004 | Train Loss: 290.6592 | Val Loss: 274.4603\n",
      "Epoch 005 | Train Loss: 218.9763 | Val Loss: 218.1858\n",
      "Epoch 006 | Train Loss: 169.5342 | Val Loss: 171.8652\n",
      "Epoch 007 | Train Loss: 135.3695 | Val Loss: 137.5897\n",
      "Epoch 008 | Train Loss: 107.5545 | Val Loss: 112.8204\n",
      "Epoch 009 | Train Loss: 86.2237 | Val Loss: 93.5092\n",
      "Epoch 010 | Train Loss: 68.9749 | Val Loss: 74.1887\n",
      "Epoch 011 | Train Loss: 55.4766 | Val Loss: 58.5250\n",
      "Epoch 012 | Train Loss: 43.3338 | Val Loss: 45.7716\n",
      "Epoch 013 | Train Loss: 33.6110 | Val Loss: 37.0280\n",
      "Epoch 014 | Train Loss: 26.4078 | Val Loss: 28.7370\n",
      "Epoch 015 | Train Loss: 21.3483 | Val Loss: 22.9239\n",
      "Epoch 016 | Train Loss: 17.7067 | Val Loss: 19.8460\n",
      "Epoch 017 | Train Loss: 15.1411 | Val Loss: 19.4057\n",
      "Epoch 018 | Train Loss: 14.4616 | Val Loss: 15.4926\n",
      "Epoch 019 | Train Loss: 12.6449 | Val Loss: 14.3420\n",
      "Epoch 020 | Train Loss: 11.6453 | Val Loss: 15.0378\n",
      "Epoch 021 | Train Loss: 11.7137 | Val Loss: 12.1456\n",
      "Epoch 022 | Train Loss: 11.0704 | Val Loss: 12.8803\n",
      "Epoch 023 | Train Loss: 10.2007 | Val Loss: 11.2736\n",
      "Epoch 024 | Train Loss: 9.9669 | Val Loss: 15.7707\n",
      "Epoch 025 | Train Loss: 9.5880 | Val Loss: 11.7505\n",
      "Epoch 026 | Train Loss: 9.4240 | Val Loss: 10.4994\n",
      "Epoch 027 | Train Loss: 9.2638 | Val Loss: 10.2279\n",
      "Epoch 028 | Train Loss: 10.1505 | Val Loss: 11.0131\n",
      "Epoch 029 | Train Loss: 9.4595 | Val Loss: 13.1504\n",
      "Epoch 030 | Train Loss: 9.2862 | Val Loss: 11.1702\n",
      "Epoch 031 | Train Loss: 9.1365 | Val Loss: 10.7692\n",
      "Epoch 032 | Train Loss: 9.9299 | Val Loss: 10.8830\n",
      "Early stopping triggered at epoch 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>train_loss</td><td>9.92993</td></tr><tr><td>val_loss</td><td>10.88297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sound-139</strong> at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/kx5oxaxg' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1/runs/kx5oxaxg</a><br> View project at: <a href='https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1' target=\"_blank\">https://wandb.ai/yixuan228-imperial-college-london/DE_Groupwork_G4_stage1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250321_060735-kx5oxaxg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for all configurations.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import torch.optim as optim\n",
    "\n",
    "for hidden_units, hidden_layers, lr in product(hidden_units_options, hidden_layers_options, learning_rates):\n",
    "\n",
    "    # Configurations\n",
    "    config = {\n",
    "        \"hidden_units\": hidden_units,\n",
    "        \"hidden_layers\": hidden_layers,\n",
    "        \"learning_rate\": lr,\n",
    "        \"max_epochs\": max_epochs,\n",
    "        \"patience\": patience\n",
    "    }\n",
    "\n",
    "    # Start a new W&B run for each configuration\n",
    "    wandb.init(project='DE_Groupwork_G4_stage1', config=config, reinit=True)\n",
    "\n",
    "    model = MultiLayerPerceptron(input_size=input_size, \n",
    "                             hidden_size=config[\"hidden_units\"], \n",
    "                             num_layers=config[\"hidden_layers\"], \n",
    "                             output_size=1).to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.MSELoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "        \n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss = train_epoch(model, train_Loader, criterion, optimizer, device)\n",
    "       \n",
    "        test_loss = val_epoch(model, test_Loader, criterion, device)\n",
    "\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": test_loss})\n",
    "        \n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "print(\"Training complete for all configurations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Summary and Select the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "project_path = \"yixuan228-imperial-college-london/DE_Groupwork G4\"\n",
    "runs = api.runs(project_path)  # Get all the runs\n",
    "\n",
    "# save_dir = \"wandb_artifacts\"\n",
    "# os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_summary, ls_config = [], []\n",
    "\n",
    "best_run = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "ls_config = [run.config for run in runs]\n",
    "ls_summary = [run.summary._json_dict for run in runs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Found:\n",
      "Run ID: nbfzlfhc, Name: fearless-morning-12, State: finished\n",
      "Lowest Validation Loss: 8.600484386515094\n",
      "\n",
      "Best Model Hyperparameters (config):\n",
      "   patience: 5\n",
      "   max_epochs: 200\n",
      "   hidden_units: 64\n",
      "   hidden_layers: 2\n",
      "   learning_rate: 0.001\n",
      "\n",
      "Best Model Final Metrics (summary):\n",
      "   _runtime: 19.7579481\n",
      "   _step: 118\n",
      "   _timestamp: 1742462047.419305\n",
      "   _wandb: {'runtime': 19}\n",
      "   epoch: 119\n",
      "   train_loss: 8.823451982218003\n",
      "   val_loss: 8.600484386515094\n"
     ]
    }
   ],
   "source": [
    "best_run = None\n",
    "best_loss = float(\"inf\")  \n",
    "\n",
    "for run in runs:\n",
    "    # print(run.summary.keys())\n",
    "    if \"val_loss\" in run.summary:  \n",
    "        loss = run.summary[\"val_loss\"]\n",
    "        if loss < best_loss:  # best model with least loss\n",
    "            best_loss = loss\n",
    "            best_run = run\n",
    "\n",
    "# Best model hyparparameters\n",
    "if best_run:\n",
    "    print(\"\\nBest Model Found:\")\n",
    "    print(f\"Run ID: {best_run.id}, Name: {best_run.name}, State: {best_run.state}\")\n",
    "    print(f\"Lowest Validation Loss: {best_loss}\")\n",
    "\n",
    "    print(\"\\nBest Model Hyperparameters (config):\")\n",
    "    for key, value in best_run.config.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "    print(\"\\nBest Model Final Metrics (summary):\")\n",
    "    for key, value in best_run.summary.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"No valid runs found with 'loss' metric.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Best NN Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Nueral Network Models is a good way to predict the CO2 emssions based on the features given. After using W&B to grid search the hyperparameters grid, the best model is chosen based on the metric of validation loss.\n",
    "\n",
    "The best model parameters are listed below:\n",
    "\n",
    "**Hyperparameter**:\\\n",
    "    patience: 5\\\n",
    "    max_epochs: 200\\\n",
    "    hidden_units: 64\\\n",
    "    hidden_layers: 2\\\n",
    "    learning_rate: 0.001\n",
    "\n",
    "**Running Performance:**\\\n",
    "    epoch: 119\\\n",
    "    Training loss: 8.823451982218003\\\n",
    "    Validation loss: 8.600484386515094\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 K-fold on Best NN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize NN model configuration, set hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hidden_size = 64    # Numbers of neurons in each hidden layer\n",
    "num_layer = 2       # Numbers of hidden layers\n",
    "learning_rate = 0.001     # Learning rates\n",
    "\n",
    "num_epochs = 200  # Arbitrarily large; early stopping will likely stop earlier.\n",
    "batch_size = 64\n",
    "patience = 5      # Early stopping patience\n",
    "\n",
    "input_size =  X_train_processed.shape[1]   # Input size \n",
    "output_size = 1             # Output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output k-fold validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Neural Network Model:\n",
      "\n",
      "Fold 1 Validation Dataset MSE: 6.1134\n",
      "Fold 2 Validation Dataset MSE: 7.3139\n",
      "Fold 3 Validation Dataset MSE: 9.6385\n",
      "Fold 4 Validation Dataset MSE: 8.6772\n",
      "Fold 5 Validation Dataset MSE: 7.9452\n",
      "Fold 6 Validation Dataset MSE: 7.5017\n",
      "Fold 7 Validation Dataset MSE: 8.4447\n",
      "Fold 8 Validation Dataset MSE: 7.7857\n",
      "Fold 9 Validation Dataset MSE: 5.7889\n",
      "Fold 10 Validation Dataset MSE: 21.0900\n",
      "Fold 11 Validation Dataset MSE: 10.2420\n",
      "Fold 12 Validation Dataset MSE: 7.1534\n",
      "Fold 13 Validation Dataset MSE: 6.6245\n",
      "Fold 14 Validation Dataset MSE: 7.0126\n",
      "Fold 15 Validation Dataset MSE: 8.3232\n",
      "Fold 16 Validation Dataset MSE: 6.4513\n",
      "Fold 17 Validation Dataset MSE: 8.5044\n",
      "Fold 18 Validation Dataset MSE: 7.0600\n",
      "Fold 19 Validation Dataset MSE: 7.4439\n",
      "Fold 20 Validation Dataset MSE: 6.1258\n",
      "\n",
      "K-Fold Average MSE: 8.2620\n",
      "\n",
      "--------Finished training and validating the model!--------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch import optim\n",
    "\n",
    "# Save MSE and True/Predict Values---------------------------\n",
    "nn_k_fold_mse = []\n",
    "nn_k_fold_R2 = []\n",
    "nn_k_fold_mae = []\n",
    "nn_k_fold_mape = []   \n",
    "\n",
    "# Train and Evaluate the model----------------------------\n",
    "print(f'Best Neural Network Model:\\n')\n",
    "for fold, (train_index, val_index) in enumerate(k_fold.split(X_train_df)):\n",
    "\n",
    "    # get the training and validation data\n",
    "    train_subset  = Subset(train_dataset, train_index)\n",
    "    val_subset = Subset(train_dataset, val_index)\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = DataLoader(dataset=train_subset , batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    nn_model = MultiLayerPerceptron(input_size, hidden_size, num_layer, output_size).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()  # MSE as loss function\n",
    "    optimizer = optim.Adam(nn_model.parameters(), lr=learning_rate)  # Adam as optimizer\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        nn_model.train()\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = nn_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # if (epoch+1) % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validate the model\n",
    "    nn_model.eval()\n",
    "\n",
    "    y_true_fold = []\n",
    "    y_pred_fold = []\n",
    "\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = nn_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # y_true_fold.append(y_batch.cpu.numpy())     \n",
    "            # y_pred_fold.append(y_pred.cpu.numpy())      \n",
    "\n",
    "            y_true_fold.append(y_batch.cpu().detach().numpy())  # true value\n",
    "            y_pred_fold.append(y_pred.cpu().detach().numpy())   # predicted value\n",
    "\n",
    "    y_true_fold = np.concatenate(y_true_fold, axis=0).flatten()\n",
    "    y_pred_fold = np.concatenate(y_pred_fold, axis=0).flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_true_fold, y_pred_fold)\n",
    "    r2 = r2_score(y_true_fold, y_pred_fold)\n",
    "    mae = mean_absolute_error(y_true_fold, y_pred_fold)\n",
    "    mape = mean_absolute_percentage_error(y_true_fold, y_pred_fold)\n",
    "\n",
    "    nn_k_fold_mse.append(mse)\n",
    "    nn_k_fold_R2.append(r2)\n",
    "    nn_k_fold_mae.append(mae)\n",
    "    nn_k_fold_mape.append(mape)\n",
    "    \n",
    "    print(f\"Fold {fold+1} Validation Dataset MSE: {mse:.4f}\")\n",
    "\n",
    "print(f\"\\nK-Fold Average MSE: {np.mean(nn_k_fold_mse):.4f}\")\n",
    "print(f\"\\n--------Finished training and validating the model!--------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model:\n",
      "    Test Dataset MSE: 8.5209\n",
      "    Test Dataset R2: 0.9976\n",
      "    Test Dataset MAE: 2.1793\n",
      "    Test Dataset MAPE: 0.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Neural Network Model: Observed vs Predicted values')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model on the test dataset------------------------   \n",
    "# Using MSE as the evaluation metrics: Mean Squared Error, R2, MAE, MAPE\n",
    "nn_model.eval()\n",
    "\n",
    "# Get the prediction and true values\n",
    "nn_test_true = []\n",
    "nn_test_pred = []\n",
    "\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_Loader:\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = nn_model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        nn_test_true.append(y_batch.cpu().detach().numpy())     # true value\n",
    "        nn_test_pred.append(y_pred.cpu().detach().numpy())      # predicted value\n",
    "\n",
    "# concatenate the true and predicted values\n",
    "nn_test_true = np.concatenate(nn_test_true, axis=0).flatten()\n",
    "nn_test_pred = np.concatenate(nn_test_pred, axis=0).flatten()\n",
    "\n",
    "nn_test_r2 = r2_score(nn_test_pred, nn_test_true)\n",
    "nn_test_mse = mean_squared_error(nn_test_pred, nn_test_true)\n",
    "nn_test_mae = mean_absolute_error(nn_test_pred, nn_test_true)\n",
    "nn_test_mape = mean_absolute_percentage_error(nn_test_pred, nn_test_true)\n",
    "\n",
    "# Output\n",
    "print(f'Neural Network Model:')\n",
    "print(f\"    Test Dataset MSE: {nn_test_mse:.4f}\")\n",
    "print(f\"    Test Dataset R2: {nn_test_r2:.4f}\")\n",
    "print(f\"    Test Dataset MAE: {nn_test_mae:.4f}\")\n",
    "print(f\"    Test Dataset MAPE: {nn_test_mape:.4f}\")\n",
    "\n",
    "# Using plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "plot_pred_true(nn_test_true, nn_test_pred, ax)\n",
    "plt.title('Neural Network Model: Observed vs Predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset MSE: 8.5209\n",
      "Validation Dataset MSE: 8.2620\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Dataset MSE: {nn_test_mse:.4f}\")\n",
    "print(f\"Validation Dataset MSE: {np.mean(nn_k_fold_mse):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Save the NN Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of Best NN Model\n",
    "\n",
    "- Output will include two types of data: Validation values, and Test Values, and combine those into one dataframe.\n",
    "\n",
    "- Validation RSE:  1 x 20    Test RSE: 1 x 1\n",
    "\n",
    "- Validation R2:   1 x 20    Test R2:  1 x 1\n",
    "\n",
    "- Validation MAE:  1 x 20    Test MAE:  1 x 1\n",
    "\n",
    "- Validation MAPE: 1 x 20    Test MAPE:  1 x 1\n",
    "\n",
    "- So the output dataframe should include:\n",
    "\n",
    "    - **4 rows**: RSE, R2, MAE and MAPE \n",
    "    \n",
    "    - **21 cols**:  first 20 as validation metrics, with the last one being test metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output of Best NN Model \n",
    "nn_metrics = pd.DataFrame([nn_k_fold_mse, nn_k_fold_R2, nn_k_fold_mae, nn_k_fold_mape])\n",
    "\n",
    "# Add Test results\n",
    "nn_metrics[\"Test_results\"] = [nn_test_mse, nn_test_r2, nn_test_mae, nn_test_mape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_metrics.columns = [f\"fold_{i+1}\" for i in range(20)] + [\"Test\"]\n",
    "nn_metrics.index = ['MSE', 'R2', 'MAE', 'MAPE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "      <th>fold_6</th>\n",
       "      <th>fold_7</th>\n",
       "      <th>fold_8</th>\n",
       "      <th>fold_9</th>\n",
       "      <th>fold_10</th>\n",
       "      <th>...</th>\n",
       "      <th>fold_12</th>\n",
       "      <th>fold_13</th>\n",
       "      <th>fold_14</th>\n",
       "      <th>fold_15</th>\n",
       "      <th>fold_16</th>\n",
       "      <th>fold_17</th>\n",
       "      <th>fold_18</th>\n",
       "      <th>fold_19</th>\n",
       "      <th>fold_20</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>6.113358</td>\n",
       "      <td>7.313945</td>\n",
       "      <td>9.638522</td>\n",
       "      <td>8.677197</td>\n",
       "      <td>7.945219</td>\n",
       "      <td>7.501666</td>\n",
       "      <td>8.444725</td>\n",
       "      <td>7.785693</td>\n",
       "      <td>5.788854</td>\n",
       "      <td>21.090017</td>\n",
       "      <td>...</td>\n",
       "      <td>7.153397</td>\n",
       "      <td>6.624498</td>\n",
       "      <td>7.012626</td>\n",
       "      <td>8.323240</td>\n",
       "      <td>6.451344</td>\n",
       "      <td>8.504441</td>\n",
       "      <td>7.060046</td>\n",
       "      <td>7.443864</td>\n",
       "      <td>6.125840</td>\n",
       "      <td>8.520922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.998153</td>\n",
       "      <td>0.998061</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>0.997541</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.997941</td>\n",
       "      <td>0.997580</td>\n",
       "      <td>0.997420</td>\n",
       "      <td>0.998318</td>\n",
       "      <td>0.994024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997937</td>\n",
       "      <td>0.997960</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.998096</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.997962</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>0.997588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.983023</td>\n",
       "      <td>2.105791</td>\n",
       "      <td>2.410057</td>\n",
       "      <td>2.394346</td>\n",
       "      <td>2.208756</td>\n",
       "      <td>2.174423</td>\n",
       "      <td>2.315574</td>\n",
       "      <td>2.165404</td>\n",
       "      <td>1.971961</td>\n",
       "      <td>2.192429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.214294</td>\n",
       "      <td>1.991784</td>\n",
       "      <td>2.153582</td>\n",
       "      <td>2.376910</td>\n",
       "      <td>2.093174</td>\n",
       "      <td>2.173668</td>\n",
       "      <td>2.091307</td>\n",
       "      <td>2.041270</td>\n",
       "      <td>1.974809</td>\n",
       "      <td>2.179332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold_1    fold_2    fold_3    fold_4    fold_5    fold_6    fold_7  \\\n",
       "MSE   6.113358  7.313945  9.638522  8.677197  7.945219  7.501666  8.444725   \n",
       "R2    0.998153  0.998061  0.997622  0.997541  0.997494  0.997941  0.997580   \n",
       "MAE   1.983023  2.105791  2.410057  2.394346  2.208756  2.174423  2.315574   \n",
       "MAPE  0.008238  0.008441  0.009456  0.009464  0.008862  0.008723  0.009460   \n",
       "\n",
       "        fold_8    fold_9    fold_10  ...   fold_12   fold_13   fold_14  \\\n",
       "MSE   7.785693  5.788854  21.090017  ...  7.153397  6.624498  7.012626   \n",
       "R2    0.997420  0.998318   0.994024  ...  0.997937  0.997960  0.997440   \n",
       "MAE   2.165404  1.971961   2.192429  ...  2.214294  1.991784  2.153582   \n",
       "MAPE  0.008676  0.008045   0.009785  ...  0.008813  0.008238  0.008685   \n",
       "\n",
       "       fold_15   fold_16   fold_17   fold_18   fold_19   fold_20      Test  \n",
       "MSE   8.323240  6.451344  8.504441  7.060046  7.443864  6.125840  8.520922  \n",
       "R2    0.997560  0.998096  0.997403  0.997962  0.997540  0.998298  0.997588  \n",
       "MAE   2.376910  2.093174  2.173668  2.091307  2.041270  1.974809  2.179332  \n",
       "MAPE  0.009314  0.008459  0.008837  0.008293  0.008268  0.007799  0.008773  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test_pred_df = pd.DataFrame(nn_test_pred, columns=[\"y\"])\n",
    "nn_test_pred_df.to_csv(\"Workstream_1_ML_models/nn_test_pred.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_metrics.to_csv(\"Best_NN_Model_performance.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_w6_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
