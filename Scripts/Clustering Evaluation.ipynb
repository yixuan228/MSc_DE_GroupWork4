{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价clustering模型的方法\n",
    "\n",
    "1. 如果有真实类别，可以计算 FPR 和 TPR 并绘制 ROC 曲线。\n",
    "\n",
    "2. Pairwise Similarity 计算样本对是否在同一聚类中，并与真实类别进行对比\n",
    "\n",
    "3. 只是想评估聚类质量，可以使用 ARI 或 NMI。\n",
    "\n",
    "真实类别数目已知、类别数相近\tARI\t调整了随机性，适用于类别稳定的情况\n",
    "\n",
    "真实类别数目可能变化\tNMI\t归一化互信息，可用于不同类别数的情况\n",
    "\n",
    "无监督聚类，无真实类别\tPairwise Similarity\t通过样本对计算相似性，可用于无标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, pairwise_distances\n",
    "\n",
    "def evaluate_clustering_models(labels_true, cluster_results, model_names):\n",
    "    \"\"\"\n",
    "    计算聚类模型的评估指标（ARI, NMI 或 Pairwise Similarity），并以表格和可视化方式展示。\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for name in model_names:\n",
    "        if labels_true is not None:\n",
    "            ari = adjusted_rand_score(labels_true, cluster_results[name])\n",
    "            nmi = normalized_mutual_info_score(labels_true, cluster_results[name])\n",
    "            metrics[name] = {\"ARI\": ari, \"NMI\": nmi}\n",
    "        else:\n",
    "            # 计算 Pairwise Similarity\n",
    "            similarity = 1 - np.mean(pairwise_distances(cluster_results[name].reshape(-1, 1)))\n",
    "            metrics[name] = {\"Pairwise Similarity\": similarity}\n",
    "    \n",
    "    # 转换为 DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    \n",
    "    # 显示指标表格\n",
    "    print(\"\\nClustering Model Performance Metrics:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # 绘制指标对比图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if labels_true is not None:\n",
    "        plt.bar(model_names, [metrics[name][\"ARI\"] for name in model_names], alpha=0.6, label=\"ARI\")\n",
    "        plt.bar(model_names, [metrics[name][\"NMI\"] for name in model_names], alpha=0.6, label=\"NMI\")\n",
    "    else:\n",
    "        plt.bar(model_names, [metrics[name][\"Pairwise Similarity\"] for name in model_names], color='blue')\n",
    "    \n",
    "    plt.xlabel(\"Models\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Comparison of Clustering Performance\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the ground truth labels\n",
    "n_classes = optimal_k  # Set n_classes to the number of clusters\n",
    "y_train_binarized = label_binarize(CO2_train_labels, classes=range(n_classes))\n",
    "y_test_binarized = label_binarize(CO2_test_labels, classes=range(n_classes))\n",
    "\n",
    "# Binarize the clustering labels\n",
    "train_kmeans_binarized = label_binarize(train_df['KMeans Cluster (Optimal)'], classes=range(optimal_k))\n",
    "test_kmeans_binarized = label_binarize(test_df['KMeans Cluster (Optimal)'], classes=range(optimal_k))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_train_binarized[:, i], train_kmeans_binarized[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_train_binarized.ravel(), train_kmeans_binarized.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})', color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KMeans Clustering')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
